I0708 14:05:09.210791   60673 main.go:647] Cluster Autoscaler 1.30.1
W0708 14:05:09.212019   60673 main.go:652] Error reading gardener autoscaler version, err: read VERSION: is a directory
I0708 14:05:09.212156   60673 client.go:47] Using kubeconfig file: /Users/i585976/go/src/github.com/mcm-poc/autoscaler-virtual/cluster-autoscaler/dev/kubeconfigs/kubeconfig_target.yaml
I0708 14:05:09.215271   60673 framework.go:373] "the scheduler starts to work with those plugins" Plugins={"PreEnqueue":{"Enabled":[{"Name":"SchedulingGates","Weight":0}],"Disabled":null},"QueueSort":{"Enabled":[{"Name":"PrioritySort","Weight":0}],"Disabled":null},"PreFilter":{"Enabled":[{"Name":"NodeAffinity","Weight":0},{"Name":"NodePorts","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeRestrictions","Weight":0},{"Name":"EBSLimits","Weight":0},{"Name":"GCEPDLimits","Weight":0},{"Name":"NodeVolumeLimits","Weight":0},{"Name":"AzureDiskLimits","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"VolumeZone","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0}],"Disabled":null},"Filter":{"Enabled":[{"Name":"NodeUnschedulable","Weight":0},{"Name":"NodeName","Weight":0},{"Name":"TaintToleration","Weight":0},{"Name":"NodeAffinity","Weight":0},{"Name":"NodePorts","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeRestrictions","Weight":0},{"Name":"EBSLimits","Weight":0},{"Name":"GCEPDLimits","Weight":0},{"Name":"NodeVolumeLimits","Weight":0},{"Name":"AzureDiskLimits","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"VolumeZone","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0}],"Disabled":null},"PostFilter":{"Enabled":[{"Name":"DefaultPreemption","Weight":0}],"Disabled":null},"PreScore":{"Enabled":[{"Name":"TaintToleration","Weight":0},{"Name":"NodeAffinity","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0},{"Name":"NodeResourcesBalancedAllocation","Weight":0}],"Disabled":null},"Score":{"Enabled":[{"Name":"TaintToleration","Weight":3},{"Name":"NodeAffinity","Weight":2},{"Name":"NodeResourcesFit","Weight":1},{"Name":"VolumeBinding","Weight":1},{"Name":"PodTopologySpread","Weight":2},{"Name":"InterPodAffinity","Weight":2},{"Name":"NodeResourcesBalancedAllocation","Weight":1},{"Name":"ImageLocality","Weight":1}],"Disabled":null},"Reserve":{"Enabled":[{"Name":"VolumeBinding","Weight":0}],"Disabled":null},"Permit":{"Enabled":null,"Disabled":null},"PreBind":{"Enabled":[{"Name":"VolumeBinding","Weight":0}],"Disabled":null},"Bind":{"Enabled":[{"Name":"DefaultBinder","Weight":0}],"Disabled":null},"PostBind":{"Enabled":null,"Disabled":null},"MultiPoint":{"Enabled":null,"Disabled":null}}
I0708 14:05:10.550406   60673 cloud_provider_builder.go:30] Building mcm cloud provider.
W0708 14:05:10.550465   60673 client_config.go:659] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
W0708 14:05:10.550473   60673 client_config.go:664] error creating inClusterConfig, falling back to default config: unable to load in-cluster configuration, KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT must be defined
I0708 14:05:11.655462   60673 reflector.go:296] Starting reflector *v1alpha1.MachineDeployment (1h0m0s) from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655482   60673 reflector.go:332] Listing and watching *v1alpha1.MachineDeployment from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655496   60673 reflector.go:296] Starting reflector *v1alpha1.MachineSet (1h0m0s) from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655502   60673 reflector.go:332] Listing and watching *v1alpha1.MachineSet from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655508   60673 reflector.go:296] Starting reflector *v1.Node (1h0m0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:11.655514   60673 reflector.go:332] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:05:11.655602   60673 reflector.go:296] Starting reflector *v1.Deployment (1h0m0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:11.655612   60673 reflector.go:332] Listing and watching *v1.Deployment from k8s.io/client-go/informers/factory.go:160
I0708 14:05:11.655462   60673 reflector.go:296] Starting reflector *v1alpha1.MachineClass (1h0m0s) from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655963   60673 reflector.go:332] Listing and watching *v1alpha1.MachineClass from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.655462   60673 reflector.go:296] Starting reflector *v1alpha1.Machine (1h0m0s) from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.656000   60673 reflector.go:332] Listing and watching *v1alpha1.Machine from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.813418   60673 reflector.go:359] Caches populated for *v1alpha1.MachineClass from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.814706   60673 reflector.go:359] Caches populated for *v1alpha1.Machine from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.814751   60673 reflector.go:359] Caches populated for *v1alpha1.MachineSet from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:11.814790   60673 reflector.go:359] Caches populated for *v1alpha1.MachineDeployment from github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120
I0708 14:05:12.114523   60673 reflector.go:359] Caches populated for *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.156539   60673 taints.go:105] Startup taint node.gardener.cloud/critical-components-not-ready on all NodeGroups
I0708 14:05:12.156566   60673 taints.go:105] Startup taint testing.node.gardener.cloud/initial-node-blocked on all NodeGroups
I0708 14:05:12.156824   60673 reflector.go:296] Starting reflector *v1.Namespace (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.156835   60673 reflector.go:332] Listing and watching *v1.Namespace from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.156855   60673 reflector.go:296] Starting reflector *v1.Pod (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.156863   60673 reflector.go:332] Listing and watching *v1.Pod from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157001   60673 reflector.go:296] Starting reflector *v1.PersistentVolumeClaim (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157013   60673 reflector.go:332] Listing and watching *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157023   60673 reflector.go:296] Starting reflector *v1.Node (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157030   60673 reflector.go:332] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157114   60673 reflector.go:296] Starting reflector *v1.CSINode (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157120   60673 reflector.go:332] Listing and watching *v1.CSINode from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157127   60673 reflector.go:296] Starting reflector *v1.PodDisruptionBudget (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157132   60673 reflector.go:332] Listing and watching *v1.PodDisruptionBudget from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157243   60673 reflector.go:296] Starting reflector *v1.ReplicationController (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157252   60673 reflector.go:332] Listing and watching *v1.ReplicationController from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157294   60673 reflector.go:296] Starting reflector *v1.CSIDriver (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157297   60673 reflector.go:296] Starting reflector *v1.Job (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157302   60673 reflector.go:332] Listing and watching *v1.Job from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.156827   60673 reflector.go:296] Starting reflector *v1.PersistentVolume (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157327   60673 reflector.go:296] Starting reflector *v1.Service (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157332   60673 reflector.go:332] Listing and watching *v1.PersistentVolume from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157352   60673 reflector.go:296] Starting reflector *v1.ReplicaSet (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157356   60673 reflector.go:332] Listing and watching *v1.ReplicaSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157385   60673 reflector.go:296] Starting reflector *v1.CSIStorageCapacity (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157390   60673 reflector.go:332] Listing and watching *v1.CSIStorageCapacity from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157411   60673 reflector.go:296] Starting reflector *v1.StorageClass (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157332   60673 reflector.go:332] Listing and watching *v1.Service from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157417   60673 reflector.go:332] Listing and watching *v1.StorageClass from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157298   60673 reflector.go:332] Listing and watching *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157455   60673 reflector.go:296] Starting reflector *v1.DaemonSet (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157459   60673 reflector.go:332] Listing and watching *v1.DaemonSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157486   60673 reflector.go:296] Starting reflector *v1.StatefulSet (0s) from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157491   60673 reflector.go:332] Listing and watching *v1.StatefulSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.157597   60673 main.go:443] Registered cleanup signal handler
I0708 14:05:12.157659   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:05:12.157755   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 88.25Âµs
I0708 14:05:12.357194   60673 request.go:629] Waited for 199.665375ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0
I0708 14:05:12.382680   60673 reflector.go:359] Caches populated for *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.382720   60673 reflector.go:359] Caches populated for *v1.Namespace from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.382967   60673 reflector.go:359] Caches populated for *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.383551   60673 reflector.go:359] Caches populated for *v1.CSINode from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.383640   60673 reflector.go:359] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.558010   60673 request.go:629] Waited for 400.494ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0
I0708 14:05:12.616912   60673 reflector.go:359] Caches populated for *v1.ReplicationController from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.618102   60673 reflector.go:359] Caches populated for *v1.Job from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.618122   60673 reflector.go:359] Caches populated for *v1.PersistentVolume from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.618933   60673 reflector.go:359] Caches populated for *v1.ReplicaSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.757318   60673 request.go:629] Waited for 599.79825ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/services?limit=500&resourceVersion=0
I0708 14:05:12.841543   60673 reflector.go:359] Caches populated for *v1.CSIStorageCapacity from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.841975   60673 reflector.go:359] Caches populated for *v1.StorageClass from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.844381   60673 reflector.go:359] Caches populated for *v1.Pod from k8s.io/client-go/informers/factory.go:160
I0708 14:05:12.958012   60673 request.go:629] Waited for 800.512625ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0
I0708 14:05:12.983491   60673 reflector.go:359] Caches populated for *v1.Service from k8s.io/client-go/informers/factory.go:160
I0708 14:05:13.160447   60673 request.go:629] Waited for 1.002861125s due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/apps/v1/daemonsets?limit=500&resourceVersion=0
I0708 14:05:13.160852   60673 request.go:697] Waited for 1.002861125s due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/apps/v1/daemonsets?limit=500&resourceVersion=0
I0708 14:05:13.183564   60673 reflector.go:359] Caches populated for *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I0708 14:05:13.186551   60673 reflector.go:359] Caches populated for *v1.Deployment from k8s.io/client-go/informers/factory.go:160
I0708 14:05:13.358004   60673 request.go:629] Waited for 1.200417s due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/apps/v1/statefulsets?limit=500&resourceVersion=0
I0708 14:05:13.390543   60673 reflector.go:359] Caches populated for *v1.DaemonSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:13.583973   60673 reflector.go:359] Caches populated for *v1.StatefulSet from k8s.io/client-go/informers/factory.go:160
I0708 14:05:22.158116   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:22.158343   60673 static_autoscaler.go:306] Starting main loop
I0708 14:05:22.158563   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:22.158599   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:22.159004   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:22.159013   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:22.159425   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:22.159435   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:22.159741   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:05:22.159968   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:22.159977   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
W0708 14:05:22.160271   60673 clusterstate.go:477] AcceptableRanges have not been populated yet. Skip checking
W0708 14:05:22.160277   60673 clusterstate.go:477] AcceptableRanges have not been populated yet. Skip checking
W0708 14:05:22.160280   60673 clusterstate.go:477] AcceptableRanges have not been populated yet. Skip checking
W0708 14:05:22.160283   60673 clusterstate.go:477] AcceptableRanges have not been populated yet. Skip checking
I0708 14:05:22.160300   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:22.160366   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:05:22.160498   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-fsjnn: cannot put pod scale-up-pod-554d49bbb5-fsjnn on any node
I0708 14:05:22.160507   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:05:22.160529   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:05:22.160534   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:05:22.160538   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:05:22.160558   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn is unschedulable
I0708 14:05:22.160635   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:05:22.160787   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-fsjnn can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:05:22.161106   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:05:22.161214   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-3265244118965205344 and template-node-for-shoot--i585976--ca-test-one-zone-z1-1851784024547383292 are not similar, ephemeral-storage does not match
I0708 14:05:22.161843   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-4192381481841923998 and template-node-for-shoot--i585976--ca-test-one-zone-z1-1851784024547383292 are not similar, ephemeral-storage does not match
I0708 14:05:22.162447   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-3886567835644809572 and template-node-for-shoot--i585976--ca-test-one-zone-z1-1851784024547383292 are not similar, ephemeral-storage does not match
I0708 14:05:22.162925   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z1 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:05:22.162939   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:05:22.162943   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z3 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:05:22.162952   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z3
I0708 14:05:22.162966   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-three-zones-z3
I0708 14:05:22.162982   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-3886567835644809572 and template-node-for-shoot--i585976--ca-test-one-zone-z1-1851784024547383292 are not similar, ephemeral-storage does not match
I0708 14:05:22.163019   60673 orchestrator.go:212] Found 2 similar node groups: [shoot--i585976--ca-test-three-zones-z1 shoot--i585976--ca-test-three-zones-z2]
I0708 14:05:22.163039   60673 orchestrator.go:247] Splitting scale-up between 3 similar node groups: {shoot--i585976--ca-test-three-zones-z3, shoot--i585976--ca-test-three-zones-z1, shoot--i585976--ca-test-three-zones-z2}
I0708 14:05:22.163054   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)}]
I0708 14:05:22.163066   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z3 size to 1
I0708 14:05:22.163106   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z3 by 1
I0708 14:05:22.163177   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"607637", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z3 size to 1 instead of 0 (max: 1)
I0708 14:05:22.327549   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W0708 14:05:22.327623   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z3
I0708 14:05:22.393474   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"607637", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z3 size set to 1 instead of 0 (max: 1)
I0708 14:05:22.621562   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-fsjnn", UID:"03c58e88-7790-4954-a11a-245cf96e1623", APIVersion:"v1", ResourceVersion:"607354", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)}]
I0708 14:05:32.783960   60673 static_autoscaler.go:306] Starting main loop
I0708 14:05:32.784083   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:32.784143   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:32.784593   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:32.784613   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:32.785103   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:32.785118   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:32.785594   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:05:32.785965   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:32.785980   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
W0708 14:05:32.786374   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z3
I0708 14:05:32.786424   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:32.786733   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:05:32.786856   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-8089708541104368106-upcoming-0
I0708 14:05:32.786870   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:05:32.786884   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:05:32.786892   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:05:32.786898   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:05:32.786922   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:05:32.786947   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:05:32.787036   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:05:32.787065   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:32.787074   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:05:32.787204   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:05:43.242985   60673 static_autoscaler.go:306] Starting main loop
I0708 14:05:43.243192   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:43.243251   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:43.243726   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:43.243750   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:43.244360   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:43.244382   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:43.245119   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:43.245139   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:43.245800   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:05:43.246393   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:43.246469   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:05:43.246836   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:05:43.246964   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-6945922887014422865-upcoming-0
I0708 14:05:43.246986   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:05:43.247002   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:05:43.247012   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:05:43.247021   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:05:43.247053   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:05:43.247083   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:05:43.247120   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:05:43.247142   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:43.247153   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:05:43.247215   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:05:53.706446   60673 static_autoscaler.go:306] Starting main loop
I0708 14:05:53.706620   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:53.706665   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:05:53.707119   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:53.707143   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:53.707782   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:53.707801   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:53.708201   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:05:53.708212   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:05:53.708516   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:05:53.708903   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:53.708951   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:05:53.709286   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:05:53.709369   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-2694377802958700023-upcoming-0
I0708 14:05:53.709380   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:05:53.709389   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:05:53.709395   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:05:53.709399   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:05:53.709416   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:05:53.709433   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:05:53.709452   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:05:53.709463   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:05:53.709469   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:05:53.709504   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:04.165686   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:04.165836   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:04.165874   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:04.166159   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:04.166170   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:04.166489   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:04.166747   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:04.166756   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:04.166980   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:04.166989   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:04.167291   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:04.167329   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:06:04.167510   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:04.167583   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-2688984300180589871-upcoming-0
I0708 14:06:04.167594   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:04.167600   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:04.167605   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:04.167608   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:04.167631   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:04.167646   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:04.167660   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:04.167670   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:04.167675   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:04.167703   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:14.628269   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:14.628513   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:14.628570   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:14.629080   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:14.629106   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:14.629765   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:14.629782   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:14.630403   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:14.630420   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:14.631060   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:14.631737   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:14.631821   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:06:14.632367   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:14.632510   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-1472821398426200585-upcoming-0
I0708 14:06:14.632533   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:14.632550   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:14.632561   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:14.632570   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:14.632604   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:14.632636   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:14.632675   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:14.632698   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:14.632710   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:14.632780   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:25.089997   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:25.090206   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:25.090272   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:25.090772   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:25.091427   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:25.091449   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:25.092051   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:25.092068   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:25.092611   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:25.092643   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:25.093311   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:25.093398   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:06:25.093759   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:25.093881   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-4433963322374566534-upcoming-0
I0708 14:06:25.093901   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:25.093917   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:25.093928   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:25.093937   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:25.093969   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:25.094005   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:25.094047   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:25.094068   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:25.094079   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:25.094140   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:35.554555   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:35.554675   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:35.554777   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:35.555272   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:35.555295   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:35.555962   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:35.556527   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:35.556546   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:35.557066   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:35.557086   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:35.557764   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:35.557844   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:06:35.558224   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:35.558355   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-5684735331680886741-upcoming-0
I0708 14:06:35.558376   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:35.558392   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:35.558402   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:35.558411   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:35.558444   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:35.558476   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:35.558507   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:35.558526   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:35.558537   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:35.558598   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:46.019813   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:46.020001   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:46.020053   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:46.020540   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:46.021242   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:46.021267   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:46.021783   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:46.021798   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:46.022406   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:46.022428   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:46.023039   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:46.023129   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:06:46.023534   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:46.023663   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-1469714098909899767-upcoming-0
I0708 14:06:46.023682   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:46.023698   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:46.023708   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:46.023717   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:46.023749   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:46.023780   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:46.023810   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:46.023831   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:46.023842   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:46.023901   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:06:56.613901   60673 static_autoscaler.go:306] Starting main loop
I0708 14:06:56.614047   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:56.614094   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:06:56.614706   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:06:56.615349   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:56.615373   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:56.615942   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:56.615964   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:56.616457   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:06:56.616476   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:06:56.617168   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:56.617576   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:06:56.617714   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-675356870047955803-upcoming-0
I0708 14:06:56.617736   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:06:56.617751   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:06:56.617762   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:06:56.617778   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:06:56.617812   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:06:56.617847   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:06:56.617884   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:06:56.617903   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:06:56.617915   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:06:56.617978   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:07:07.081892   60673 static_autoscaler.go:306] Starting main loop
I0708 14:07:07.082186   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:07.082259   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:07.083033   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:07:07.083712   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:07.083725   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:07.084046   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:07.084055   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:07.084320   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:07.084330   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:07:07.084750   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:07.085173   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:07:07.085314   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-1379795099694558653-upcoming-0
I0708 14:07:07.085326   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:07:07.085336   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:07:07.085342   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:07:07.085346   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:07:07.085359   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:07:07.085373   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:07:07.085393   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:07:07.085403   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:07.085407   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:07:07.085452   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:05:22.157822 +0530 IST m=+12.981231126 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:07:12.159530   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:07:12.159835   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 231.708Âµs
I0708 14:07:17.592898   60673 static_autoscaler.go:306] Starting main loop
I0708 14:07:17.593254   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:17.593326   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:17.593366   60673 taints.go:442] Overriding status of node ip-10-180-153-85.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:07:17.594302   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:07:17.595329   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:17.595354   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:17.595965   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:17.595983   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:07:17.596549   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:17.596569   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:17.597314   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:17.597934   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:07:17.598138   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-9151934734354126203-upcoming-0
I0708 14:07:17.598243   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-fsjnn: cannot put pod scale-up-pod-554d49bbb5-fsjnn on any node
I0708 14:07:17.598442   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-wkk26 based on similar pods scheduling
I0708 14:07:17.598462   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:07:17.598479   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:07:17.598493   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:07:17.598502   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 2 unschedulable pods left
I0708 14:07:17.598525   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn is unschedulable
I0708 14:07:17.598537   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 is unschedulable
I0708 14:07:17.598668   60673 orchestrator.go:111] Upcoming 1 nodes
I0708 14:07:17.598833   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:07:17.598989   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-fsjnn can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:07:17.599006   60673 orchestrator.go:568] 1 other pods similar to scale-up-pod-554d49bbb5-fsjnn can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:07:17.599286   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:07:17.599336   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-9052341264792815184 and template-node-for-shoot--i585976--ca-test-one-zone-z1-3945088141654066135 are not similar, ephemeral-storage does not match
I0708 14:07:17.600482   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-8082640633903001645 and template-node-for-shoot--i585976--ca-test-one-zone-z1-3945088141654066135 are not similar, ephemeral-storage does not match
I0708 14:07:17.601595   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z1 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:07:17.601624   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I0708 14:07:17.601646   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z1
I0708 14:07:17.601663   60673 orchestrator.go:188] Estimated 2 nodes needed in shoot--i585976--ca-test-three-zones-z1
I0708 14:07:17.601703   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-9052341264792815184 and template-node-for-shoot--i585976--ca-test-one-zone-z1-3945088141654066135 are not similar, ephemeral-storage does not match
I0708 14:07:17.601822   60673 orchestrator.go:212] Found 1 similar node groups: [shoot--i585976--ca-test-three-zones-z2]
I0708 14:07:17.601875   60673 orchestrator.go:247] Splitting scale-up between 2 similar node groups: {shoot--i585976--ca-test-three-zones-z1, shoot--i585976--ca-test-three-zones-z2}
I0708 14:07:17.601909   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:07:17.601945   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1
I0708 14:07:17.601986   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z2 by 1
I0708 14:07:17.602071   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"608428", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1 instead of 0 (max: 1)
I0708 14:07:17.766325   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z1 size to 2
I0708 14:07:17.766378   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z1 by 1
I0708 14:07:17.967038   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I0708 14:07:18.139280   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"608428", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z2 size set to 1 instead of 0 (max: 1)
I0708 14:07:18.371097   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"608428", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z1 size to 2 instead of 1 (max: 2)
I0708 14:07:18.600276   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"608428", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z1 size set to 2 instead of 1 (max: 2)
I0708 14:07:18.828291   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-wkk26", UID:"848ef312-4248-4dd8-aa04-45fb818f879a", APIVersion:"v1", ResourceVersion:"608476", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:07:28.597048   60673 static_autoscaler.go:306] Starting main loop
I0708 14:07:28.597238   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:28.597302   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:28.597344   60673 taints.go:442] Overriding status of node ip-10-180-153-85.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:07:28.598276   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:07:28.599067   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:28.599091   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:28.599748   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:28.599769   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:28.600322   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:28.600342   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:28.601144   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:28.601294   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:07:28.602643   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:07:28.602865   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-1884581601522957031-upcoming-0
I0708 14:07:28.602983   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-8646848101797261384-upcoming-0
I0708 14:07:28.603064   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-4801892588817261608-upcoming-0
I0708 14:07:28.603097   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:07:28.603116   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:07:28.603129   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:07:28.603138   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:07:28.603172   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:07:28.603205   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:07:28.603258   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:28.603294   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:07:28.603408   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:07:28.603527   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:07:28.603607   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:07:28.603695   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 0s
I0708 14:07:28.603797   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:07:28.603869   60673 static_autoscaler.go:655] Starting scale down
I0708 14:07:28.603934   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 0s
I0708 14:07:28.604222   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:29.064884   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:07:39.524605   60673 static_autoscaler.go:306] Starting main loop
I0708 14:07:39.524890   60673 taints.go:442] Overriding status of node ip-10-180-153-85.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:07:39.524967   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:39.525018   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:39.525937   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:07:39.526717   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:39.526746   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:39.527342   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:39.527361   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:07:39.527893   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:39.527907   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:07:39.528945   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:39.529100   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:07:39.530339   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:07:39.530523   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-6318457072380671947-upcoming-0
I0708 14:07:39.530623   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-fsjnn can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-3294226763106547553-upcoming-0
I0708 14:07:39.530792   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-8907243652696804819-upcoming-0
I0708 14:07:39.530816   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:07:39.530831   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:07:39.530840   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:07:39.530845   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:07:39.530864   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:07:39.530883   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:07:39.530926   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:39.530937   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:07:39.531041   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:07:39.531074   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:07:39.531126   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:07:39.531179   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 10.927580542s
I0708 14:07:39.531290   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:07:39.531338   60673 static_autoscaler.go:655] Starting scale down
I0708 14:07:39.531379   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 10.927580542s
I0708 14:07:39.531454   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:50.065765   60673 static_autoscaler.go:306] Starting main loop
I0708 14:07:50.066068   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:50.066166   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:07:50.067161   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:07:50.068067   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:50.068093   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:50.068751   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:50.068786   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:07:50.069486   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:07:50.069517   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:07:50.070481   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:50.070607   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z3 finished successfully in 2m27.737547833s
I0708 14:07:50.070686   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:07:50.071613   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:07:50.071823   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-2630844282071460562-upcoming-0
I0708 14:07:50.071941   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-2979158180385314271-upcoming-0
I0708 14:07:50.071964   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:07:50.071983   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:07:50.071998   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:07:50.072007   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:07:50.072040   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:07:50.072078   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:07:50.072136   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:07:50.072156   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:07:50.072397   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:07:50.072623   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:07:50.072663   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:07:50.072710   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:07:50.072750   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 21.46867725s
I0708 14:07:50.072838   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:07:50.072897   60673 static_autoscaler.go:655] Starting scale down
I0708 14:07:50.072943   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 21.46867725s
I0708 14:07:50.073050   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:00.716333   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:00.716635   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:00.716712   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:00.717622   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:00.718524   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:00.718549   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:00.719146   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:00.719166   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:08:00.719781   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:00.719801   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:08:00.720589   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:00.720755   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:08:00.721658   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:00.721834   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4510736442317871726-upcoming-0
I0708 14:08:00.721947   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-7454980645460934133-upcoming-0
I0708 14:08:00.721969   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:00.721989   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:00.722002   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:00.722011   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:00.722051   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:00.722085   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:00.722138   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:00.722155   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:00.722374   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:00.722492   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:00.722523   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:00.722569   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:00.722602   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 32.119201917s
I0708 14:08:00.722698   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:00.722757   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:00.722806   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 32.119201917s
I0708 14:08:00.722905   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:11.263683   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:11.264031   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:11.264114   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:11.265068   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:11.265863   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:11.265888   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:11.266527   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:11.266550   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:11.267126   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:11.267147   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:11.267949   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:11.268097   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:08:11.268948   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:11.269130   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-7304439566622342794-upcoming-0
I0708 14:08:11.269216   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-7104108852061155015-upcoming-0
I0708 14:08:11.269235   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:11.269255   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:11.269267   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:11.269276   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:11.269313   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:11.269345   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:11.269395   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:11.269411   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:11.269617   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:11.269740   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:11.269770   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:11.269815   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:11.269845   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 42.666053667s
I0708 14:08:11.269925   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:11.269988   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:11.270042   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 42.666053667s
I0708 14:08:11.270125   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:21.727099   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:21.727279   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:21.727323   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:21.728786   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:21.729230   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:21.729241   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:21.729477   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:21.729487   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:08:21.729919   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:21.730010   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:08:21.730790   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:21.730942   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-1889477503457039422-upcoming-0
I0708 14:08:21.731035   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-1694964987992254246-upcoming-0
I0708 14:08:21.731055   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:21.731073   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:21.731086   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:21.731139   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:21.731182   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:21.731216   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:21.731283   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:21.731299   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:21.731468   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:21.731534   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:21.731552   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:21.731579   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:21.731596   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 53.129031917s
I0708 14:08:21.731639   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:21.731665   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:21.731693   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 53.129031917s
I0708 14:08:21.731745   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:32.192932   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:32.193135   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:32.193208   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:32.195125   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:32.195860   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:32.195885   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:32.196409   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:32.196428   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:32.197137   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:32.197286   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:08:32.198088   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:32.198284   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-7917160429234526359-upcoming-0
I0708 14:08:32.198365   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-5736400629960008325-upcoming-0
I0708 14:08:32.198393   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:32.198411   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:32.198425   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:32.198433   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:32.198468   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:32.198501   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:32.198548   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:32.198567   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:32.198857   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:32.198967   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:32.198997   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:32.199040   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:32.199073   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m3.594645667s
I0708 14:08:32.199157   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:32.199236   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:32.199287   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m3.594645667s
I0708 14:08:32.199378   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:43.208135   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:43.208353   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:43.208424   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:43.210936   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:43.211664   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:43.211688   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-73-8.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:08:43.212212   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:43.212233   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:43.212913   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:43.213832   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:43.214041   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-9154996330558648006-upcoming-0
I0708 14:08:43.214147   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-8382410683619963201-upcoming-0
I0708 14:08:43.214187   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:43.214208   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:43.214221   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:43.214230   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:43.214268   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:43.214300   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:43.214356   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:43.214374   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:43.214586   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:43.214710   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:43.214743   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:43.214794   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:43.214833   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m14.609697583s
I0708 14:08:43.214916   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:43.214971   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:43.215022   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m14.609697583s
I0708 14:08:43.215112   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:53.702374   60673 static_autoscaler.go:306] Starting main loop
I0708 14:08:53.702660   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:53.702727   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:08:53.704918   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:53.704945   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-73-8.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:08:53.705752   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:08:53.705775   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:08:53.706327   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:08:53.707062   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:53.707915   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:08:53.708121   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-nznw9 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-2841162416995009488-upcoming-0
I0708 14:08:53.708214   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-wkk26 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6504335569232297117-upcoming-0
I0708 14:08:53.708236   60673 filter_out_schedulable.go:120] 2 pods marked as unschedulable can be scheduled.
I0708 14:08:53.708254   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:08:53.708268   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:08:53.708277   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:08:53.708312   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:08:53.708347   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:08:53.708397   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:08:53.708414   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:08:53.708595   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:08:53.708734   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:08:53.708765   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:08:53.708811   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:08:53.708846   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m25.10383275s
I0708 14:08:53.708944   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:08:53.709010   60673 static_autoscaler.go:655] Starting scale down
I0708 14:08:53.709058   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m25.10383275s
I0708 14:08:53.709144   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:04.274465   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:04.274764   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:04.274835   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:04.277274   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:04.277309   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-17-19.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:09:04.278069   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:04.278094   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:04.278690   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:04.279406   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:04.280298   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:04.280323   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:04.280344   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:04.280356   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:04.280384   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:04.280419   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:04.280451   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:04.280495   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:04.280511   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:04.280706   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:04.280891   60673 eligibility.go:162] Node ip-10-180-153-85.eu-west-1.compute.internal unremovable: cpu requested (75.8333% of allocatable) is above the scale-down utilization threshold
I0708 14:09:04.280931   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:09:04.280985   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:09:04.281017   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m35.675828125s
I0708 14:09:04.281102   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:09:04.281155   60673 static_autoscaler.go:655] Starting scale down
I0708 14:09:04.281203   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m35.675828125s
I0708 14:09:04.281303   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:12.162800   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:09:12.163140   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 250.958Âµs
I0708 14:09:14.741691   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:14.741889   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:14.741939   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:14.743435   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:14.743461   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-17-19.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:09:14.744118   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:14.744589   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:14.744618   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:09:14.745318   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:14.745381   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z2 finished successfully in 1m56.973622458s
I0708 14:09:14.745401   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z1 finished successfully in 1m56.772946042s
I0708 14:09:14.745475   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:14.745492   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:14.745509   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:14.745519   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:14.745529   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:14.745562   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:14.745596   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:14.745643   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:14.745658   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:14.745877   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:14.745974   60673 klogx.go:87] Node ip-10-180-73-8.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:14.746054   60673 klogx.go:87] Node ip-10-180-153-85.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:14.746136   60673 klogx.go:87] Node ip-10-180-17-19.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:14.746159   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:09:14.746198   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:09:14.746222   60673 cluster.go:156] Simulating node ip-10-180-73-8.eu-west-1.compute.internal removal
I0708 14:09:14.746254   60673 cluster.go:174] node ip-10-180-73-8.eu-west-1.compute.internal may be removed
I0708 14:09:14.746281   60673 cluster.go:156] Simulating node ip-10-180-153-85.eu-west-1.compute.internal removal
I0708 14:09:14.746308   60673 cluster.go:174] node ip-10-180-153-85.eu-west-1.compute.internal may be removed
I0708 14:09:14.746331   60673 cluster.go:156] Simulating node ip-10-180-17-19.eu-west-1.compute.internal removal
I0708 14:09:14.746360   60673 cluster.go:174] node ip-10-180-17-19.eu-west-1.compute.internal may be removed
I0708 14:09:14.746388   60673 nodes.go:84] ip-10-180-73-8.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 0s
I0708 14:09:14.746407   60673 nodes.go:84] ip-10-180-153-85.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 0s
I0708 14:09:14.746417   60673 nodes.go:84] ip-10-180-17-19.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 0s
I0708 14:09:14.746428   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m46.143035375s
I0708 14:09:14.746525   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:09:14.746578   60673 static_autoscaler.go:655] Starting scale down
I0708 14:09:14.746617   60673 nodes.go:126] ip-10-180-17-19.eu-west-1.compute.internal was unneeded for 0s
I0708 14:09:14.746647   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m46.143035375s
I0708 14:09:14.746672   60673 nodes.go:126] ip-10-180-73-8.eu-west-1.compute.internal was unneeded for 0s
I0708 14:09:14.746691   60673 nodes.go:126] ip-10-180-153-85.eu-west-1.compute.internal was unneeded for 0s
I0708 14:09:14.746777   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:15.194379   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-73-8.eu-west-1.compute.internal
I0708 14:09:15.432264   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-153-85.eu-west-1.compute.internal
I0708 14:09:15.664882   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-17-19.eu-west-1.compute.internal
I0708 14:09:26.221450   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:26.221669   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:26.221721   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:26.222526   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:09:26.223341   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:26.223365   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-153-85.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:09:26.223901   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:26.224394   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:26.224413   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:26.224987   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:26.225078   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:26.225096   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:26.225112   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:26.225122   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:26.225130   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:26.225162   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:26.225194   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:26.225254   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:26.225270   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:26.225499   60673 klogx.go:87] Node ip-10-180-17-19.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:26.225584   60673 klogx.go:87] Node ip-10-180-73-8.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:26.225655   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:26.225732   60673 klogx.go:87] Node ip-10-180-153-85.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:09:26.225751   60673 cluster.go:156] Simulating node ip-10-180-17-19.eu-west-1.compute.internal removal
I0708 14:09:26.225788   60673 cluster.go:174] node ip-10-180-17-19.eu-west-1.compute.internal may be removed
I0708 14:09:26.225813   60673 cluster.go:156] Simulating node ip-10-180-73-8.eu-west-1.compute.internal removal
I0708 14:09:26.225844   60673 cluster.go:174] node ip-10-180-73-8.eu-west-1.compute.internal may be removed
I0708 14:09:26.225877   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:09:26.225908   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:09:26.225931   60673 cluster.go:156] Simulating node ip-10-180-153-85.eu-west-1.compute.internal removal
I0708 14:09:26.225958   60673 cluster.go:174] node ip-10-180-153-85.eu-west-1.compute.internal may be removed
I0708 14:09:26.225989   60673 nodes.go:84] ip-10-180-17-19.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 11.479696625s
I0708 14:09:26.226009   60673 nodes.go:84] ip-10-180-73-8.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 11.479696625s
I0708 14:09:26.226021   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:07:28.596891 +0530 IST m=+139.419660543 duration 1m57.622732s
I0708 14:09:26.226031   60673 nodes.go:84] ip-10-180-153-85.eu-west-1.compute.internal is unneeded since 2024-07-08 14:09:14.741646 +0530 IST m=+245.562695918 duration 11.479696625s
I0708 14:09:26.226133   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:09:26.226185   60673 static_autoscaler.go:655] Starting scale down
I0708 14:09:26.226224   60673 nodes.go:126] ip-10-180-73-8.eu-west-1.compute.internal was unneeded for 11.479696625s
I0708 14:09:26.226258   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m57.622732s
I0708 14:09:26.226280   60673 nodes.go:126] ip-10-180-153-85.eu-west-1.compute.internal was unneeded for 11.479696625s
I0708 14:09:26.226303   60673 nodes.go:126] ip-10-180-17-19.eu-west-1.compute.internal was unneeded for 11.479696625s
I0708 14:09:26.226338   60673 klogx.go:87] Considering node ip-10-180-73-8.eu-west-1.compute.internal for standard scale down
I0708 14:09:26.226362   60673 klogx.go:87] Considering node ip-10-180-153-85.eu-west-1.compute.internal for standard scale down
I0708 14:09:26.226380   60673 klogx.go:87] Considering node ip-10-180-17-19.eu-west-1.compute.internal for standard scale down
I0708 14:09:26.460363   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-73-8.eu-west-1.compute.internal
I0708 14:09:26.460505   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-73-8.eu-west-1.compute.internal", UID:"0dd0a62b-e586-4937-bab1-70447416b174", APIVersion:"v1", ResourceVersion:"609642", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:09:26.908833   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-153-85.eu-west-1.compute.internal
I0708 14:09:26.908998   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-153-85.eu-west-1.compute.internal", UID:"09b13639-5cf8-4564-9ca1-c18b399f745a", APIVersion:"v1", ResourceVersion:"609552", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:09:27.142784   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-17-19.eu-west-1.compute.internal
I0708 14:09:27.142887   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-73-8.eu-west-1.compute.internal"
I0708 14:09:27.142953   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-17-19.eu-west-1.compute.internal", UID:"edda67bb-06fe-4a01-b55f-56cefd650964", APIVersion:"v1", ResourceVersion:"609553", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:09:27.143028   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-153-85.eu-west-1.compute.internal"
I0708 14:09:27.143143   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-17-19.eu-west-1.compute.internal"
I0708 14:09:27.143364   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:09:27.143384   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:09:27.143435   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:09:27.382127   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609578", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-73-8.eu-west-1.compute.internal"
I0708 14:09:27.689452   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609578", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-153-85.eu-west-1.compute.internal"
I0708 14:09:27.995132   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609578", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-17-19.eu-west-1.compute.internal"
I0708 14:09:32.143940   60673 drain.go:131] All pods removed from ip-10-180-17-19.eu-west-1.compute.internal
I0708 14:09:32.143940   60673 drain.go:131] All pods removed from ip-10-180-153-85.eu-west-1.compute.internal
I0708 14:09:32.143956   60673 drain.go:131] All pods removed from ip-10-180-73-8.eu-west-1.compute.internal
I0708 14:09:32.144032   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-17-19.eu-west-1.compute.internal]
I0708 14:09:32.144063   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-153-85.eu-west-1.compute.internal]
I0708 14:09:32.144073   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-73-8.eu-west-1.compute.internal]
I0708 14:09:32.449378   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z1-66665-5h6rn marked with priority 1 successfully
I0708 14:09:32.449409   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z1-66665-5h6rn:ip-10-180-17-19.eu-west-1.compute.internal]
I0708 14:09:32.462614   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-thmdj marked with priority 1 successfully
I0708 14:09:32.462638   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z3-577bb-42hvk marked with priority 1 successfully
I0708 14:09:32.462639   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z2-55dc4-thmdj:ip-10-180-73-8.eu-west-1.compute.internal]
I0708 14:09:32.462709   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z3-577bb-42hvk:ip-10-180-153-85.eu-west-1.compute.internal]
I0708 14:09:32.612538   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z1 size decreased to 1 
I0708 14:09:32.612712   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609674", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-17-19.eu-west-1.compute.internal removed
I0708 14:09:32.628693   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z2 size decreased to 0 
I0708 14:09:32.630153   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z3 size decreased to 0 
I0708 14:09:32.841934   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609674", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-73-8.eu-west-1.compute.internal removed
I0708 14:09:33.071347   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"609674", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-153-85.eu-west-1.compute.internal removed
I0708 14:09:37.690603   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:37.690904   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:37.690959   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:37.691762   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:09:37.691781   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:09:37.692591   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:37.693129   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:37.693151   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-17-19.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:09:37.693650   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:37.693670   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:37.694272   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:37.694372   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:37.694390   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:37.694406   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:37.694415   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:37.694424   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:37.694457   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:37.694488   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:37.694520   60673 pre_filtering_processor.go:67] Skipping ip-10-180-17-19.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:09:37.694538   60673 pre_filtering_processor.go:67] Skipping ip-10-180-73-8.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:09:37.694554   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:09:37.694575   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:37.694587   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:37.694607   60673 pre_filtering_processor.go:67] Skipping ip-10-180-153-85.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:09:37.694669   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:09:48.157446   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:48.157629   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:48.157693   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:48.158884   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:09:48.158906   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:09:48.160141   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:48.160825   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:48.160849   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:48.161411   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:48.161432   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:48.162065   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:48.162213   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:48.162236   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:48.162259   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:48.162270   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:48.162282   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:48.162316   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:48.162350   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:48.162392   60673 pre_filtering_processor.go:67] Skipping ip-10-180-73-8.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:09:48.162415   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:09:48.162434   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:48.162447   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:48.162468   60673 pre_filtering_processor.go:67] Skipping ip-10-180-153-85.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:09:48.162487   60673 pre_filtering_processor.go:67] Skipping ip-10-180-17-19.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:09:48.162564   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:09:58.924371   60673 static_autoscaler.go:306] Starting main loop
I0708 14:09:58.924581   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:58.924638   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:09:59.090827   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z1-66665-5h6rn marked with priority 1 successfully
I0708 14:09:59.263287   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-thmdj marked with priority 1 successfully
I0708 14:09:59.432831   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z3-577bb-42hvk marked with priority 1 successfully
I0708 14:09:59.433595   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:59.433622   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:59.434435   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:09:59.434998   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:59.435021   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:59.435526   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:09:59.435547   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:09:59.436147   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:59.436289   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:09:59.436378   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:09:59.436401   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:09:59.436456   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:09:59.436474   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:09:59.436485   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:09:59.436521   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:09:59.436562   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:09:59.436613   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:09:59.436641   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:09:59.436653   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:09:59.436682   60673 pre_filtering_processor.go:67] Skipping ip-10-180-153-85.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:09:59.436769   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:07:17.592783 +0530 IST m=+128.415608376 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:10:09.893622   60673 static_autoscaler.go:306] Starting main loop
I0708 14:10:09.893790   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:09.893846   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:09.894629   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:10:09.895384   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:09.895408   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:09.895950   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:09.895966   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:09.896460   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:09.896481   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:09.897072   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:09.897097   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:09.897110   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:09.897198   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:10:09.897217   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-07857a7a4e432674f"
I0708 14:10:09.897227   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-07857a7a4e432674f, it's either been removed or it's not managed by this controller
W0708 14:10:09.897241   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-07857a7a4e432674f
I0708 14:10:09.897273   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:09.897286   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:09.897299   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:10:09.897369   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:10:09.897392   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:09.897406   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:09.897466   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:10:09.897486   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-07857a7a4e432674f"
I0708 14:10:09.897497   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-07857a7a4e432674f, it's either been removed or it's not managed by this controller
W0708 14:10:09.897505   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-07857a7a4e432674f, skipping
I0708 14:10:09.897522   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:09.897533   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:09.897542   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:10:09.897593   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:10:09.897752   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-4x27p: cannot put pod scale-up-pod-554d49bbb5-4x27p on any node
I0708 14:10:09.897778   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:10:09.897797   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:10:09.897808   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:10:09.897818   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:10:09.897857   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p is unschedulable
I0708 14:10:09.897893   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:10:09.898092   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-4x27p can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:10:09.898421   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:10:09.898474   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-1544988505616246447 and template-node-for-shoot--i585976--ca-test-one-zone-z1-2840660756848015016 are not similar, ephemeral-storage does not match
I0708 14:10:09.899101   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-7678991249101553027 and template-node-for-shoot--i585976--ca-test-one-zone-z1-2840660756848015016 are not similar, ephemeral-storage does not match
I0708 14:10:09.899598   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-5393206227310570128 and template-node-for-shoot--i585976--ca-test-one-zone-z1-2840660756848015016 are not similar, ephemeral-storage does not match
I0708 14:10:09.900107   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z1 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:10:09.900136   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:10:09.900150   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z3 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:10:09.900173   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z2
I0708 14:10:09.900191   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-three-zones-z2
I0708 14:10:09.900226   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-7678991249101553027 and template-node-for-shoot--i585976--ca-test-one-zone-z1-2840660756848015016 are not similar, ephemeral-storage does not match
I0708 14:10:09.900332   60673 orchestrator.go:212] Found 2 similar node groups: [shoot--i585976--ca-test-three-zones-z1 shoot--i585976--ca-test-three-zones-z3]
I0708 14:10:09.900386   60673 orchestrator.go:247] Splitting scale-up between 3 similar node groups: {shoot--i585976--ca-test-three-zones-z2, shoot--i585976--ca-test-three-zones-z1, shoot--i585976--ca-test-three-zones-z3}
I0708 14:10:09.900422   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:10:09.900452   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1
I0708 14:10:09.900494   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z2 by 1
I0708 14:10:10.065720   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W0708 14:10:10.065797   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:10:10.065976   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-4x27p", UID:"3ce9a780-bb71-45ab-8b38-f23838f473ba", APIVersion:"v1", ResourceVersion:"609925", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:10:20.525351   60673 static_autoscaler.go:306] Starting main loop
I0708 14:10:20.525631   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:20.525696   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:20.526510   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:20.526537   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:20.527261   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:20.527277   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:20.527819   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:10:20.528328   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:20.528349   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
W0708 14:10:20.528822   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:10:20.528898   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:20.528940   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:20.528954   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:20.528975   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:10:20.528990   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-07857a7a4e432674f"
I0708 14:10:20.529001   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-07857a7a4e432674f, it's either been removed or it's not managed by this controller
W0708 14:10:20.529016   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-07857a7a4e432674f
I0708 14:10:20.529031   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:20.529042   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:20.529061   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:10:20.529161   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:10:20.529186   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:20.529199   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:20.529212   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:10:20.529226   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-07857a7a4e432674f"
I0708 14:10:20.529236   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-07857a7a4e432674f, it's either been removed or it's not managed by this controller
W0708 14:10:20.529246   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-07857a7a4e432674f, skipping
I0708 14:10:20.529261   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:20.529271   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:20.529281   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:10:20.529660   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:10:20.529856   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4517537307390501319-upcoming-0
I0708 14:10:20.529878   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:10:20.529896   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:10:20.529908   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:10:20.529918   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:10:20.529951   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:10:20.529986   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:10:20.530021   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:20.530036   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:10:20.530062   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:10:20.530146   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:10:21.613067   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSINode total 14 items received
I0708 14:10:29.611573   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0708 14:10:31.041557   60673 static_autoscaler.go:306] Starting main loop
I0708 14:10:31.041811   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:31.041858   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:31.042461   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:10:31.042983   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:31.042995   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:31.043302   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:31.043311   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:31.043598   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:31.043607   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:31.043949   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:31.043974   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:31.043980   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:31.043990   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:10:31.043997   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:31.044001   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:31.044006   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:10:31.044044   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:10:31.044054   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:31.044059   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:31.044064   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:10:31.044076   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:31.044085   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:31.044089   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:10:31.044279   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:10:31.044398   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-83094571366515374-upcoming-0
I0708 14:10:31.044408   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:10:31.044417   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:10:31.044424   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:10:31.044427   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:10:31.044441   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:10:31.044454   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:10:31.044473   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:10:31.044482   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:31.044486   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:10:31.044524   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:10:33.068777   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.StorageClass total 5 items received
I0708 14:10:37.071012   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Pod total 200 items received
I0708 14:10:41.504600   60673 static_autoscaler.go:306] Starting main loop
I0708 14:10:41.504840   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:41.504897   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:41.505659   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:10:41.506473   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:41.506498   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:41.507102   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:41.507129   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:41.507663   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:41.507684   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:41.508323   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:41.508350   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:41.508364   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:41.508385   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:10:41.508423   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:41.508434   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:41.508446   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:10:41.508524   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:10:41.508550   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:41.508564   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:41.508578   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:10:41.508605   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:41.508618   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:41.508628   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:10:41.509028   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:10:41.509221   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-2219884837509084163-upcoming-0
I0708 14:10:41.509244   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:10:41.509265   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:10:41.509279   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:10:41.509287   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:10:41.509321   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:10:41.509357   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:10:41.509398   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:10:41.509422   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:41.509433   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:10:41.509508   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:10:42.972525   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.Machine total 69 items received
I0708 14:10:44.084586   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PodDisruptionBudget total 6 items received
I0708 14:10:49.845367   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.ReplicationController total 3 items received
I0708 14:10:51.966306   60673 static_autoscaler.go:306] Starting main loop
I0708 14:10:51.966577   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:51.966635   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:10:51.967378   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:10:51.968216   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:51.968244   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:51.968774   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:51.968793   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:51.969277   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:10:51.969296   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:10:51.969972   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:51.970000   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:51.970014   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:51.970033   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:10:51.970068   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:51.970081   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:51.970095   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:10:51.970173   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:10:51.970197   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:10:51.970247   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:10:51.970278   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:10:51.970326   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:10:51.970339   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:10:51.970349   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:10:51.970954   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:10:51.971154   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-9157583729195083926-upcoming-0
I0708 14:10:51.971179   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:10:51.971204   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:10:51.971217   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:10:51.971226   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:10:51.971260   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:10:51.971296   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:10:51.971341   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:10:51.971367   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:10:51.971378   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:10:51.971455   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:02.582665   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:02.582862   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:02.582918   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:02.583668   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:02.584537   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:02.584567   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:02.585082   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:02.585104   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:02.585627   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:02.585662   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:02.586351   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:02.586401   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:11:02.586438   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:11:02.586459   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0c0b0cec1686f4ab1
I0708 14:11:02.586499   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:11:02.586514   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:11:02.586528   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0b31e310e4c1a4346
I0708 14:11:02.586609   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:11:02.586630   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0c0b0cec1686f4ab1"
I0708 14:11:02.586641   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, it's either been removed or it's not managed by this controller
W0708 14:11:02.586654   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0c0b0cec1686f4ab1, skipping
I0708 14:11:02.586681   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0b31e310e4c1a4346"
I0708 14:11:02.586693   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0b31e310e4c1a4346, it's either been removed or it's not managed by this controller
W0708 14:11:02.586702   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0b31e310e4c1a4346, skipping
I0708 14:11:02.587124   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:02.587322   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-5702892474771172788-upcoming-0
I0708 14:11:02.587348   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:11:02.587368   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:11:02.587381   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:02.587390   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:02.587425   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:02.587457   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:02.587487   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:02.587503   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:02.587525   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:02.587619   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:07.846442   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PersistentVolume total 2 items received
I0708 14:11:12.164643   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:11:12.164907   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 147.25Âµs
I0708 14:11:13.045427   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:13.045630   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:13.045779   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:13.046332   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:13.046761   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:13.046771   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:13.047139   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:13.047149   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:13.047476   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:13.047485   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:13.047891   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:13.047955   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:11:13.048295   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:13.048441   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-2697779702721199075-upcoming-0
I0708 14:11:13.048454   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:11:13.048464   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:11:13.048471   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:13.048475   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:13.048488   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:13.048502   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:13.048525   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:13.048563   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:13.048569   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:13.048618   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:23.507305   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:23.507587   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:23.507652   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:23.508595   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:23.509435   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:23.509461   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:23.510069   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:23.510093   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:23.510646   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:23.510667   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:23.511387   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:23.511891   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:23.512092   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-5891639155820482635-upcoming-0
I0708 14:11:23.512116   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:11:23.512137   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:11:23.512150   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:23.512159   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:23.512194   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:23.512230   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:23.512277   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:23.512300   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:23.512311   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:23.512388   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:31.387651   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Deployment total 10 items received
I0708 14:11:34.156842   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:34.156921   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:34.156950   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:34.157296   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:34.157689   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:34.157703   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:34.157958   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:34.157967   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:34.158180   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:34.158188   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:34.158493   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:34.158706   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:34.158781   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-1201466559038975021-upcoming-0
I0708 14:11:34.158791   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:11:34.158799   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:11:34.158804   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:34.158807   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:34.158821   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:34.158833   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:34.158849   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:34.158861   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:34.158866   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:34.158897   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:36.211510   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Service total 0 items received
I0708 14:11:44.668559   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:44.668716   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:44.668765   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:44.669088   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:44.669381   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:44.669391   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:44.669582   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:44.669589   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:44.669807   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:44.669814   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:44.670088   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:44.670273   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:44.670345   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-4x27p can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-3383986438087425746-upcoming-0
I0708 14:11:44.670364   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:11:44.670371   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:11:44.670375   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:44.670379   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:44.670392   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:44.670404   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:44.670418   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:44.670425   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:44.670430   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:44.670458   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:11:55.137340   60673 static_autoscaler.go:306] Starting main loop
I0708 14:11:55.137429   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:55.137453   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:11:55.137815   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:11:55.138138   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:55.138149   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:55.138379   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:55.138389   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:55.138583   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:11:55.138591   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:11:55.138869   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:55.138889   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z2 finished successfully in 1m45.0711275s
I0708 14:11:55.138929   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:11:55.138937   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:11:55.138945   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:11:55.138949   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:11:55.138953   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:11:55.138966   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:11:55.138979   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:11:55.138993   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:11:55.139003   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:55.139009   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:11:55.139026   60673 eligibility.go:119] Skipping ip-10-180-72-241.eu-west-1.compute.internal from delete consideration - the node is marked as no scale down
I0708 14:11:55.139051   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:11:55.139078   60673 static_autoscaler.go:655] Starting scale down
I0708 14:11:55.139120   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:11:55.139168   60673 taints.go:317] Releasing taint {Key:DeletionCandidateOfClusterAutoscaler Value:1720427848 Effect:PreferNoSchedule TimeAdded:<nil>} on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:11:55.658620   60673 taints.go:352] Successfully released DeletionCandidateOfClusterAutoscaler on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:12:06.197935   60673 static_autoscaler.go:306] Starting main loop
I0708 14:12:06.198058   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:06.198085   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:06.198444   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:06.198458   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:06.198753   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:06.198763   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:06.198980   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:06.198989   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:06.199222   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:12:06.199468   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:06.199529   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:12:06.199539   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:12:06.199546   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:12:06.199551   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:12:06.199555   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:12:06.199568   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:12:06.199580   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:12:06.199591   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:06.199598   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:12:06.199610   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:12:06.199657   60673 klogx.go:87] Node ip-10-180-72-241.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:12:06.199674   60673 cluster.go:156] Simulating node ip-10-180-72-241.eu-west-1.compute.internal removal
I0708 14:12:06.199700   60673 cluster.go:174] node ip-10-180-72-241.eu-west-1.compute.internal may be removed
I0708 14:12:06.199714   60673 nodes.go:84] ip-10-180-72-241.eu-west-1.compute.internal is unneeded since 2024-07-08 14:12:06.197902 +0530 IST m=+417.018027960 duration 0s
I0708 14:12:06.199756   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:12:06.199796   60673 static_autoscaler.go:655] Starting scale down
I0708 14:12:06.199823   60673 nodes.go:126] ip-10-180-72-241.eu-west-1.compute.internal was unneeded for 0s
I0708 14:12:06.199862   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:07.946382   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-72-241.eu-west-1.compute.internal
I0708 14:12:18.562468   60673 static_autoscaler.go:306] Starting main loop
I0708 14:12:18.562565   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:18.562613   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:18.562945   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:12:18.563225   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:18.563236   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:18.563463   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:18.563471   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-72-241.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:12:18.563672   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:18.563680   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:18.563975   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:18.564028   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:12:18.564037   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:12:18.564045   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:12:18.564049   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:12:18.564053   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:12:18.564065   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:12:18.564078   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:12:18.564092   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:12:18.564106   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:18.564111   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:12:18.564166   60673 klogx.go:87] Node ip-10-180-72-241.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:12:18.564182   60673 cluster.go:156] Simulating node ip-10-180-72-241.eu-west-1.compute.internal removal
I0708 14:12:18.564208   60673 cluster.go:174] node ip-10-180-72-241.eu-west-1.compute.internal may be removed
I0708 14:12:18.564223   60673 nodes.go:84] ip-10-180-72-241.eu-west-1.compute.internal is unneeded since 2024-07-08 14:12:06.197902 +0530 IST m=+417.018027960 duration 12.364471s
I0708 14:12:18.564256   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:09:26.22141 +0530 IST m=+257.042392543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:12:18.564289   60673 static_autoscaler.go:655] Starting scale down
I0708 14:12:18.564314   60673 nodes.go:126] ip-10-180-72-241.eu-west-1.compute.internal was unneeded for 12.364471s
I0708 14:12:18.564337   60673 klogx.go:87] Considering node ip-10-180-72-241.eu-west-1.compute.internal for standard scale down
I0708 14:12:19.106650   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-72-241.eu-west-1.compute.internal
I0708 14:12:19.106701   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-72-241.eu-west-1.compute.internal"
I0708 14:12:19.106752   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-72-241.eu-west-1.compute.internal", UID:"0697d77d-65ce-4afb-a87b-5f343fb35d3b", APIVersion:"v1", ResourceVersion:"611004", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:12:19.106972   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:12:19.415002   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"610963", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-72-241.eu-west-1.compute.internal"
I0708 14:12:24.109244   60673 drain.go:131] All pods removed from ip-10-180-72-241.eu-west-1.compute.internal
I0708 14:12:24.109335   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-72-241.eu-west-1.compute.internal]
I0708 14:12:24.276985   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-pj4zn marked with priority 1 successfully
I0708 14:12:24.277006   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z2-55dc4-pj4zn:ip-10-180-72-241.eu-west-1.compute.internal]
I0708 14:12:24.440390   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z2 size decreased to 0 
I0708 14:12:24.440478   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611052", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-72-241.eu-west-1.compute.internal removed
I0708 14:12:27.611344   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Node total 136 items received
I0708 14:12:27.968825   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineClass total 14 items received
I0708 14:12:29.723222   60673 static_autoscaler.go:306] Starting main loop
I0708 14:12:29.723302   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:29.723326   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:29.723654   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:29.723666   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-72-241.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:12:29.723962   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:12:29.724169   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:29.724178   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:29.724399   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:29.724407   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:29.724651   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:29.724703   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:12:29.724711   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:12:29.724719   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:12:29.724724   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:12:29.724727   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:12:29.724740   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:12:29.724754   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:12:29.724772   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:12:29.724782   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:29.724786   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:12:29.724796   60673 pre_filtering_processor.go:67] Skipping ip-10-180-72-241.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:12:29.724825   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:12:40.183932   60673 static_autoscaler.go:306] Starting main loop
I0708 14:12:40.184016   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:40.184051   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:40.184387   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:12:40.184670   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:40.184681   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:40.184900   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:40.184909   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:40.185108   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:40.185115   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:40.185361   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:40.185406   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:12:40.185414   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:12:40.185421   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:12:40.185426   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:12:40.185429   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:12:40.185451   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:12:40.185465   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:12:40.185480   60673 pre_filtering_processor.go:67] Skipping ip-10-180-72-241.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:12:40.185490   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:12:40.185497   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:40.185502   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:12:40.185532   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:12:50.746114   60673 static_autoscaler.go:306] Starting main loop
I0708 14:12:50.746220   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:50.746246   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:12:50.912664   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-pj4zn marked with priority 1 successfully
I0708 14:12:50.912940   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:50.912951   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:50.913240   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:12:50.913440   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:50.913448   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:50.913642   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:12:50.913650   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:12:50.913891   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:50.913932   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:12:50.913962   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:12:50.913970   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:12:50.913977   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:12:50.913982   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:12:50.913985   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:12:50.913998   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:12:50.914011   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:12:50.914025   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:12:50.914035   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:12:50.914039   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:12:50.914069   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:10:09.893502 +0530 IST m=+300.714246418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:13:01.371097   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:01.371194   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:01.371220   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:01.371493   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:01.371504   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:01.371795   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:01.371808   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:01.372037   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:01.372269   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:01.372279   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:01.372526   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:01.372537   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a50b6c4880ebe20d"
I0708 14:13:01.372543   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a50b6c4880ebe20d, it's either been removed or it's not managed by this controller
W0708 14:13:01.372550   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-0a50b6c4880ebe20d
I0708 14:13:01.372584   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:13:01.372591   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a50b6c4880ebe20d"
I0708 14:13:01.372596   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a50b6c4880ebe20d, it's either been removed or it's not managed by this controller
W0708 14:13:01.372600   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-0a50b6c4880ebe20d, skipping
I0708 14:13:01.372627   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:01.372690   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5: cannot put pod scale-up-pod-554d49bbb5-47dl5 on any node
I0708 14:13:01.372756   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:13:01.372787   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:13:01.372818   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-slh2v based on similar pods scheduling
I0708 14:13:01.372846   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-rqrr6 based on similar pods scheduling
I0708 14:13:01.372879   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s6k8k based on similar pods scheduling
I0708 14:13:01.372907   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm based on similar pods scheduling
I0708 14:13:01.372934   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:13:01.372941   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:13:01.372949   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:13:01.372953   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:01.372958   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 8 unschedulable pods left
I0708 14:13:01.372965   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:13:01.372968   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:13:01.372971   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:13:01.372973   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v is unschedulable
I0708 14:13:01.372975   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 is unschedulable
I0708 14:13:01.372978   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k is unschedulable
I0708 14:13:01.372981   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:13:01.372983   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:13:01.373165   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:13:01.373291   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-47dl5 can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:01.373298   60673 orchestrator.go:568] 7 other pods similar to scale-up-pod-554d49bbb5-47dl5 can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:01.373405   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-8049966171126143386 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5181394186884390515 are not similar, ephemeral-storage does not match
I0708 14:13:01.373960   60673 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I0708 14:13:01.373975   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:01.374012   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-7709037659409158196 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5181394186884390515 are not similar, ephemeral-storage does not match
I0708 14:13:01.374515   60673 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I0708 14:13:01.374557   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-19443959558297550 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5181394186884390515 are not similar, ephemeral-storage does not match
I0708 14:13:01.375074   60673 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I0708 14:13:01.375090   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z3 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:13:01.375104   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z1 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:13:01.375108   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 50.00% CPU, 98.04% Memory, 74.02% Blended
I0708 14:13:01.375117   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z3
I0708 14:13:01.375124   60673 orchestrator.go:188] Estimated 3 nodes needed in shoot--i585976--ca-test-three-zones-z3
I0708 14:13:01.375141   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-8049966171126143386 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5181394186884390515 are not similar, ephemeral-storage does not match
I0708 14:13:01.375190   60673 orchestrator.go:212] Found 2 similar node groups: [shoot--i585976--ca-test-three-zones-z1 shoot--i585976--ca-test-three-zones-z2]
I0708 14:13:01.375226   60673 orchestrator.go:247] Splitting scale-up between 3 similar node groups: {shoot--i585976--ca-test-three-zones-z3, shoot--i585976--ca-test-three-zones-z1, shoot--i585976--ca-test-three-zones-z2}
I0708 14:13:01.375246   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:13:01.375263   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z3 size to 1
I0708 14:13:01.375284   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z3 by 1
I0708 14:13:01.375437   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z3 size to 1 instead of 0 (max: 1)
I0708 14:13:01.542137   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1
I0708 14:13:01.542167   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z2 by 1
I0708 14:13:01.609930   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z3 size set to 1 instead of 0 (max: 1)
I0708 14:13:01.704887   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z1 size to 2
I0708 14:13:01.704911   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z1 by 1
I0708 14:13:01.840253   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1 instead of 0 (max: 1)
I0708 14:13:01.871493   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I0708 14:13:02.068216   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z2 size set to 1 instead of 0 (max: 1)
I0708 14:13:02.297358   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z1 size to 2 instead of 1 (max: 2)
I0708 14:13:02.527760   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"611242", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z1 size set to 2 instead of 1 (max: 2)
I0708 14:13:02.756324   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-47dl5", UID:"a223412b-3baa-43a6-b674-0396a5c76042", APIVersion:"v1", ResourceVersion:"611272", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:13:02.982811   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-s8q6n", UID:"a1b9666c-659a-4956-857b-305bab3f069c", APIVersion:"v1", ResourceVersion:"611276", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:13:03.262017   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-d4tsm", UID:"fc89c50b-87b0-4269-a162-ac67c135f572", APIVersion:"v1", ResourceVersion:"611266", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z3 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)} {shoot--i585976--ca-test-three-zones-z1 1->2 (max: 2)}]
I0708 14:13:12.167171   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:13:12.167300   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 98.834Âµs
I0708 14:13:12.330179   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:12.330298   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:12.330323   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:12.330641   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:12.330940   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:12.330952   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:12.331166   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:12.331174   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:12.331357   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:12.331365   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:12.331656   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:12.331725   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:13:12.332200   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:12.332261   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-927224465230026727-upcoming-0
I0708 14:13:12.332290   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4442158851686291160-upcoming-0
I0708 14:13:12.332327   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-6409060335302842177-upcoming-0
I0708 14:13:12.332365   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm: cannot put pod scale-up-pod-554d49bbb5-jg9lm on any node
I0708 14:13:12.332431   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:13:12.332464   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5 based on similar pods scheduling
I0708 14:13:12.332496   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:13:12.332529   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:13:12.332536   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:13:12.332543   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:13:12.332548   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:12.332552   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:13:12.332561   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:13:12.332565   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:13:12.332568   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:13:12.332571   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:13:12.332574   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:13:12.332687   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:13:12.332709   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:13:12.332713   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:13:12.332716   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:13:12.332771   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:12.332778   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:12.332786   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:12.332792   60673 orchestrator.go:167] No expansion options
I0708 14:13:12.332839   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:13:12.332860   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:12.332856   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-jg9lm", UID:"79ed9fb7-76ab-4063-8766-3f34b42cf6cf", APIVersion:"v1", ResourceVersion:"611259", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:12.332866   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:13:12.332956   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:13:12.332973   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:13:12.332999   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:13:12.333015   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 0s
I0708 14:13:12.333049   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:13:12.333069   60673 static_autoscaler.go:655] Starting scale down
I0708 14:13:12.333087   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 0s
I0708 14:13:12.333126   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:12.559922   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-lkfjx", UID:"ec76adf4-0690-4e6c-9c6e-9b0be4ab1214", APIVersion:"v1", ResourceVersion:"611274", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:12.686857   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:13:12.908662   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-47dl5", UID:"a223412b-3baa-43a6-b674-0396a5c76042", APIVersion:"v1", ResourceVersion:"611272", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 3 max node group size reached, 1 node(s) didn't match Pod's node affinity/selector
I0708 14:13:13.139800   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-s8q6n", UID:"a1b9666c-659a-4956-857b-305bab3f069c", APIVersion:"v1", ResourceVersion:"611276", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:13.368427   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-d4tsm", UID:"fc89c50b-87b0-4269-a162-ac67c135f572", APIVersion:"v1", ResourceVersion:"611266", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 3 max node group size reached, 1 node(s) didn't match Pod's node affinity/selector
I0708 14:13:15.836400   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.StatefulSet total 3 items received
I0708 14:13:23.148591   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:23.148691   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:23.148718   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:23.148998   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:23.149009   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:23.149287   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:23.149296   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:23.149554   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:23.149565   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:23.149782   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:23.150111   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:23.150205   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:13:23.150654   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:23.150722   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-7240079059700215417-upcoming-0
I0708 14:13:23.150755   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4518273633445618975-upcoming-0
I0708 14:13:23.150787   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-5295507435690731471-upcoming-0
I0708 14:13:23.150828   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5: cannot put pod scale-up-pod-554d49bbb5-47dl5 on any node
I0708 14:13:23.150936   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:13:23.150971   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:13:23.151003   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-rqrr6 based on similar pods scheduling
I0708 14:13:23.151035   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-slh2v based on similar pods scheduling
I0708 14:13:23.151042   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:13:23.151049   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:13:23.151065   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:23.151070   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:13:23.151078   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:13:23.151081   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:13:23.151083   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:13:23.151086   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 is unschedulable
I0708 14:13:23.151088   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v is unschedulable
I0708 14:13:23.151205   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:13:23.151224   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:13:23.151228   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:13:23.151232   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:13:23.151297   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-47dl5 can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:23.151305   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-47dl5 can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:23.151314   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:23.151320   60673 orchestrator.go:167] No expansion options
I0708 14:13:23.151365   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:13:23.151386   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:23.151394   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:13:23.151441   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:13:23.151457   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:13:23.151481   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:13:23.151494   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 10.818354959s
I0708 14:13:23.151528   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:13:23.151548   60673 static_autoscaler.go:655] Starting scale down
I0708 14:13:23.151567   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 10.818354959s
I0708 14:13:23.151611   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:23.151644   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-rqrr6", UID:"38511b94-0371-45c4-8cbd-72308cde067a", APIVersion:"v1", ResourceVersion:"611269", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:23.379084   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-slh2v", UID:"fff71f00-5e93-4d57-a9d5-b7bbfcd8f8e1", APIVersion:"v1", ResourceVersion:"611268", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:27.617239   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.DaemonSet total 109 items received
I0708 14:13:33.608727   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:33.608806   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:33.608837   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:33.609137   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:33.609443   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:33.609453   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:33.609686   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:33.609694   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:33.609932   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:33.609940   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:33.610270   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:33.610337   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:13:33.610799   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:33.610865   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-4798317299890775770-upcoming-0
I0708 14:13:33.610894   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4644774451354058192-upcoming-0
I0708 14:13:33.610922   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-4745294602787381542-upcoming-0
I0708 14:13:33.610959   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm: cannot put pod scale-up-pod-554d49bbb5-jg9lm on any node
I0708 14:13:33.611023   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:13:33.611056   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5 based on similar pods scheduling
I0708 14:13:33.611086   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:13:33.611117   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:13:33.611125   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:13:33.611133   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:13:33.611138   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:33.611142   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:13:33.611150   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:13:33.611153   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:13:33.611156   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:13:33.611158   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:13:33.611161   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:13:33.611274   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:13:33.611293   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:13:33.611298   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:13:33.611307   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:13:33.611361   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:33.611369   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:33.611379   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:33.611384   60673 orchestrator.go:167] No expansion options
I0708 14:13:33.611429   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:13:33.611450   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:33.611456   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:13:33.611502   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:13:33.611518   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:13:33.611543   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:13:33.611558   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 21.278412667s
I0708 14:13:33.611590   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:13:33.611609   60673 static_autoscaler.go:655] Starting scale down
I0708 14:13:33.611627   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 21.278412667s
I0708 14:13:33.611661   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:39.901624   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Job total 4 items received
I0708 14:13:44.090940   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:44.091041   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:44.091072   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:44.091384   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:44.091395   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:44.091692   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:44.091906   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:44.091914   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:44.092105   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:44.092113   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:44.092413   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:44.092477   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:13:44.092919   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:44.092999   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-2646630479004849694-upcoming-0
I0708 14:13:44.093038   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-5482430901866743022-upcoming-0
I0708 14:13:44.093089   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-7549247857793366284-upcoming-0
I0708 14:13:44.093132   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm: cannot put pod scale-up-pod-554d49bbb5-jg9lm on any node
I0708 14:13:44.093199   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:13:44.093237   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5 based on similar pods scheduling
I0708 14:13:44.093266   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:13:44.093301   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:13:44.093308   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:13:44.093315   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:13:44.093320   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:44.093324   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:13:44.093331   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:13:44.093335   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:13:44.093338   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:13:44.093340   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:13:44.093348   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:13:44.093492   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:13:44.093509   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:13:44.093518   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:13:44.093522   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:13:44.093639   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:44.093645   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:44.093654   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:44.093660   60673 orchestrator.go:167] No expansion options
I0708 14:13:44.093702   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:13:44.093722   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:44.093728   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:13:44.093788   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:13:44.093803   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:13:44.093828   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:13:44.093843   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 31.7605925s
I0708 14:13:44.093878   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:13:44.093898   60673 static_autoscaler.go:655] Starting scale down
I0708 14:13:44.093913   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 31.7605925s
I0708 14:13:44.093955   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:54.991253   60673 static_autoscaler.go:306] Starting main loop
I0708 14:13:54.991380   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:54.991404   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:13:54.991688   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:13:54.991994   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:54.992002   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:54.992200   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:54.992208   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:54.992412   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:13:54.992418   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:13:54.992693   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:54.992762   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:13:54.993200   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:13:54.993267   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-2984876024274194149-upcoming-0
I0708 14:13:54.993302   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6996578994991966138-upcoming-0
I0708 14:13:54.993325   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-8927346974827519031-upcoming-0
I0708 14:13:54.993365   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-slh2v: cannot put pod scale-up-pod-554d49bbb5-slh2v on any node
I0708 14:13:54.993431   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-rqrr6 based on similar pods scheduling
I0708 14:13:54.993464   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s6k8k based on similar pods scheduling
I0708 14:13:54.993494   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm based on similar pods scheduling
I0708 14:13:54.993523   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:13:54.993530   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:13:54.993537   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:13:54.993542   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:13:54.993546   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:13:54.993554   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v is unschedulable
I0708 14:13:54.993557   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 is unschedulable
I0708 14:13:54.993560   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k is unschedulable
I0708 14:13:54.993563   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:13:54.993566   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:13:54.993678   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:13:54.993700   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:13:54.993705   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:13:54.993708   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:13:54.993766   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-slh2v can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:13:54.993773   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-slh2v can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:13:54.993782   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:13:54.993788   60673 orchestrator.go:167] No expansion options
I0708 14:13:54.993829   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:13:54.993853   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:13:54.993860   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:13:54.993901   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:13:54.993916   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:13:54.993939   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:13:54.993954   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 42.660840375s
I0708 14:13:54.993992   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:13:54.994012   60673 static_autoscaler.go:655] Starting scale down
I0708 14:13:54.994030   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 42.660840375s
I0708 14:13:54.994049   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-554d49bbb5-s6k8k", UID:"3166af81-692b-4b84-9c64-86716084ace9", APIVersion:"v1", ResourceVersion:"611262", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I0708 14:13:54.994073   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:05.570545   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:05.570719   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:05.570803   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:05.571494   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:05.571518   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:05.572135   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:05.572159   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:05.572669   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:05.572691   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-22-182.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:14:05.573177   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:05.573856   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:05.573975   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:14:05.574828   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:05.574897   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6942224384265468072-upcoming-0
I0708 14:14:05.574936   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-8474348570411682950-upcoming-0
I0708 14:14:05.574974   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-8523606037074177023-upcoming-0
I0708 14:14:05.575011   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-slh2v: cannot put pod scale-up-pod-554d49bbb5-slh2v on any node
I0708 14:14:05.575074   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-rqrr6 based on similar pods scheduling
I0708 14:14:05.575106   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s6k8k based on similar pods scheduling
I0708 14:14:05.575150   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm based on similar pods scheduling
I0708 14:14:05.575180   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:14:05.575187   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:14:05.575195   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:14:05.575200   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:05.575204   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:14:05.575211   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v is unschedulable
I0708 14:14:05.575215   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 is unschedulable
I0708 14:14:05.575217   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k is unschedulable
I0708 14:14:05.575219   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:14:05.575222   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:14:05.575325   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:14:05.575346   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:14:05.575352   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:14:05.575362   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:14:05.575413   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-slh2v can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:14:05.575421   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-slh2v can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:14:05.575430   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:14:05.575436   60673 orchestrator.go:167] No expansion options
I0708 14:14:05.575483   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:05.575502   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:05.575508   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:05.575567   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:05.575582   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:05.575606   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:05.575620   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 53.240063042s
I0708 14:14:05.575651   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:05.575682   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:05.575698   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 53.240063042s
I0708 14:14:05.575736   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:16.036009   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:16.036092   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:16.036116   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:16.036536   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:16.036546   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:16.036855   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:16.036864   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:14:16.037077   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:16.037085   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:16.037276   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:16.037561   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:16.038076   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:16.038140   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-7694257710782996355-upcoming-0
I0708 14:14:16.038224   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-2508663506661798085-upcoming-0
I0708 14:14:16.038307   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-7378821982424334928-upcoming-0
I0708 14:14:16.038391   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx: cannot put pod scale-up-pod-554d49bbb5-lkfjx on any node
I0708 14:14:16.038513   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm based on similar pods scheduling
I0708 14:14:16.038579   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5 based on similar pods scheduling
I0708 14:14:16.038613   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:14:16.038646   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:14:16.038653   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:14:16.038661   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:14:16.038666   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:16.038670   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:14:16.038679   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:14:16.038682   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:14:16.038684   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:14:16.038688   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:14:16.038691   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:14:16.038802   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:14:16.038819   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:14:16.038829   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:14:16.038833   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:14:16.038884   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-lkfjx can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:14:16.038892   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-lkfjx can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:14:16.038902   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:14:16.038908   60673 orchestrator.go:167] No expansion options
I0708 14:14:16.038952   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:16.038970   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:16.038976   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:16.039026   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:16.039041   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:16.039068   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:16.039083   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 1m3.705459584s
I0708 14:14:16.039117   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:16.039135   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:16.039153   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m3.705459584s
I0708 14:14:16.039187   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:19.845215   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.ReplicaSet total 27 items received
I0708 14:14:26.495618   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:26.495751   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:26.495775   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:26.495788   60673 taints.go:442] Overriding status of node ip-10-180-22-182.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:14:26.496257   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:26.496550   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:26.496559   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-22-182.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:14:26.496768   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:26.496776   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:26.496976   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:26.496985   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:14:26.497280   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:26.497733   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:26.497802   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-slh2v can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-7191871975584969095-upcoming-0
I0708 14:14:26.497831   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-rqrr6 can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z3-5869343168310615363-upcoming-0
I0708 14:14:26.497859   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s6k8k can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z1-59142638720197571-upcoming-0
I0708 14:14:26.497894   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-jg9lm: cannot put pod scale-up-pod-554d49bbb5-jg9lm on any node
I0708 14:14:26.497956   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-lkfjx based on similar pods scheduling
I0708 14:14:26.497986   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-47dl5 based on similar pods scheduling
I0708 14:14:26.498016   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-s8q6n based on similar pods scheduling
I0708 14:14:26.498051   60673 klogx.go:87] failed to find place for default/scale-up-pod-554d49bbb5-d4tsm based on similar pods scheduling
I0708 14:14:26.498058   60673 filter_out_schedulable.go:120] 3 pods marked as unschedulable can be scheduled.
I0708 14:14:26.498065   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:14:26.498072   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:26.498099   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I0708 14:14:26.498117   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-jg9lm is unschedulable
I0708 14:14:26.498124   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-lkfjx is unschedulable
I0708 14:14:26.498131   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-47dl5 is unschedulable
I0708 14:14:26.498139   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-s8q6n is unschedulable
I0708 14:14:26.498145   60673 klogx.go:87] Pod default/scale-up-pod-554d49bbb5-d4tsm is unschedulable
I0708 14:14:26.498414   60673 orchestrator.go:111] Upcoming 3 nodes
I0708 14:14:26.498461   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z1 - max size reached
I0708 14:14:26.498471   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z2 - max size reached
I0708 14:14:26.498480   60673 orchestrator.go:407] Skipping node group shoot--i585976--ca-test-three-zones-z3 - max size reached
I0708 14:14:26.498597   60673 orchestrator.go:566] Pod default/scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:14:26.498614   60673 orchestrator.go:568] 4 other pods similar to scale-up-pod-554d49bbb5-jg9lm can't be scheduled on shoot--i585976--ca-test-one-zone-z1
I0708 14:14:26.498635   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:14:26.498650   60673 orchestrator.go:167] No expansion options
I0708 14:14:26.498742   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:26.498784   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:26.498791   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:26.498837   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:26.498854   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:26.498879   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:26.498894   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 1m14.16504525s
I0708 14:14:26.498932   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:26.498953   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:26.498969   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m14.16504525s
I0708 14:14:26.499003   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:34.412337   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSIDriver total 0 items received
I0708 14:14:37.032151   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:37.032267   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:37.032289   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:37.032306   60673 taints.go:442] Overriding status of node ip-10-180-22-182.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:14:37.032321   60673 taints.go:442] Overriding status of node ip-10-180-152-11.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:14:37.032333   60673 taints.go:442] Overriding status of node ip-10-180-68-47.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:14:37.032758   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:37.033039   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:37.033048   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:37.033263   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:37.033274   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:14:37.033465   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:37.033473   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:37.033738   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:37.034187   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:37.034200   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:14:37.034208   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:14:37.034212   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:37.034217   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:14:37.034230   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:14:37.034243   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:37.034260   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:37.034267   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:37.034310   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:37.034325   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:37.034350   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:37.034363   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 1m24.701521709s
I0708 14:14:37.034394   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:37.034415   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:37.034434   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m24.701521709s
I0708 14:14:37.034470   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:37.971506   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineSet total 51 items received
I0708 14:14:44.616341   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Namespace total 11 items received
I0708 14:14:47.043226   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineDeployment total 61 items received
I0708 14:14:47.491088   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:47.491208   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:47.491232   60673 taints.go:442] Overriding status of node ip-10-180-68-47.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:14:47.491251   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:47.491730   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:47.492048   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:47.492058   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:47.492296   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:47.492304   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:47.492526   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:47.492534   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:47.492863   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:47.492879   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z3 finished successfully in 1m45.948389958s
I0708 14:14:47.492889   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z1 finished successfully in 1m45.619051792s
I0708 14:14:47.493081   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:47.493089   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:14:47.493096   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:14:47.493101   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:47.493105   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:14:47.493117   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:14:47.493129   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:47.493158   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:47.493167   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:47.493268   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:47.493307   60673 klogx.go:87] Node ip-10-180-22-182.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:47.493345   60673 klogx.go:87] Node ip-10-180-152-11.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:47.493355   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:47.493374   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:47.493391   60673 cluster.go:156] Simulating node ip-10-180-22-182.eu-west-1.compute.internal removal
I0708 14:14:47.493403   60673 cluster.go:174] node ip-10-180-22-182.eu-west-1.compute.internal may be removed
I0708 14:14:47.493412   60673 cluster.go:156] Simulating node ip-10-180-152-11.eu-west-1.compute.internal removal
I0708 14:14:47.493431   60673 cluster.go:174] node ip-10-180-152-11.eu-west-1.compute.internal may be removed
I0708 14:14:47.493444   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 1m35.160399292s
I0708 14:14:47.493456   60673 nodes.go:84] ip-10-180-22-182.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:47.491055 +0530 IST m=+578.310322293 duration 0s
I0708 14:14:47.493460   60673 nodes.go:84] ip-10-180-152-11.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:47.491055 +0530 IST m=+578.310322293 duration 0s
I0708 14:14:47.493492   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:47.493514   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:47.493532   60673 nodes.go:126] ip-10-180-152-11.eu-west-1.compute.internal was unneeded for 0s
I0708 14:14:47.493544   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m35.160399292s
I0708 14:14:47.493552   60673 nodes.go:126] ip-10-180-22-182.eu-west-1.compute.internal was unneeded for 0s
I0708 14:14:47.493592   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:47.729612   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-22-182.eu-west-1.compute.internal
I0708 14:14:48.165432   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-152-11.eu-west-1.compute.internal
I0708 14:14:58.620531   60673 static_autoscaler.go:306] Starting main loop
I0708 14:14:58.620663   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:58.620691   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:14:58.621126   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:58.621135   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:58.621458   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:58.621467   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-152-11.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:14:58.621710   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:14:58.621933   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:14:58.621940   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:14:58.622251   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:58.622282   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z2 finished successfully in 1m56.915033166s
I0708 14:14:58.622323   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:14:58.622331   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:14:58.622338   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:14:58.622342   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:14:58.622345   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:14:58.622358   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:14:58.622370   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:14:58.622388   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:14:58.622394   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:14:58.622509   60673 klogx.go:87] Node ip-10-180-29-171.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:58.622546   60673 klogx.go:87] Node ip-10-180-22-182.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:58.622579   60673 klogx.go:87] Node ip-10-180-152-11.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:58.622610   60673 klogx.go:87] Node ip-10-180-68-47.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:14:58.622620   60673 cluster.go:156] Simulating node ip-10-180-29-171.eu-west-1.compute.internal removal
I0708 14:14:58.622638   60673 cluster.go:174] node ip-10-180-29-171.eu-west-1.compute.internal may be removed
I0708 14:14:58.622649   60673 cluster.go:156] Simulating node ip-10-180-22-182.eu-west-1.compute.internal removal
I0708 14:14:58.622661   60673 cluster.go:174] node ip-10-180-22-182.eu-west-1.compute.internal may be removed
I0708 14:14:58.622670   60673 cluster.go:156] Simulating node ip-10-180-152-11.eu-west-1.compute.internal removal
I0708 14:14:58.622682   60673 cluster.go:174] node ip-10-180-152-11.eu-west-1.compute.internal may be removed
I0708 14:14:58.622695   60673 cluster.go:156] Simulating node ip-10-180-68-47.eu-west-1.compute.internal removal
I0708 14:14:58.622707   60673 cluster.go:174] node ip-10-180-68-47.eu-west-1.compute.internal may be removed
I0708 14:14:58.622719   60673 nodes.go:84] ip-10-180-29-171.eu-west-1.compute.internal is unneeded since 2024-07-08 14:13:12.330149 +0530 IST m=+483.149923001 duration 1m46.289785875s
I0708 14:14:58.622734   60673 nodes.go:84] ip-10-180-22-182.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:47.491055 +0530 IST m=+578.310322293 duration 11.129386583s
I0708 14:14:58.622739   60673 nodes.go:84] ip-10-180-152-11.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:47.491055 +0530 IST m=+578.310322293 duration 11.129386583s
I0708 14:14:58.622742   60673 nodes.go:84] ip-10-180-68-47.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:58.620501 +0530 IST m=+589.439708876 duration 0s
I0708 14:14:58.622780   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:12:18.562439 +0530 IST m=+429.382498960 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:14:58.622805   60673 static_autoscaler.go:655] Starting scale down
I0708 14:14:58.622842   60673 nodes.go:126] ip-10-180-152-11.eu-west-1.compute.internal was unneeded for 11.129386583s
I0708 14:14:58.622857   60673 nodes.go:126] ip-10-180-68-47.eu-west-1.compute.internal was unneeded for 0s
I0708 14:14:58.622868   60673 nodes.go:126] ip-10-180-29-171.eu-west-1.compute.internal was unneeded for 1m46.289785875s
I0708 14:14:58.622876   60673 nodes.go:126] ip-10-180-22-182.eu-west-1.compute.internal was unneeded for 11.129386583s
I0708 14:14:58.622897   60673 klogx.go:87] Considering node ip-10-180-152-11.eu-west-1.compute.internal for standard scale down
I0708 14:14:58.622906   60673 klogx.go:87] Considering node ip-10-180-22-182.eu-west-1.compute.internal for standard scale down
I0708 14:14:58.855936   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-152-11.eu-west-1.compute.internal
I0708 14:14:58.856023   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-152-11.eu-west-1.compute.internal", UID:"22fbc11a-56fd-459c-9040-91442593b0bf", APIVersion:"v1", ResourceVersion:"612459", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:14:59.079096   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSIStorageCapacity total 4 items received
I0708 14:14:59.089680   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-22-182.eu-west-1.compute.internal
I0708 14:14:59.089706   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-152-11.eu-west-1.compute.internal"
I0708 14:14:59.089753   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-22-182.eu-west-1.compute.internal", UID:"a481d139-995a-4f12-a3b0-6a85cd9c5f31", APIVersion:"v1", ResourceVersion:"612442", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:14:59.089797   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-22-182.eu-west-1.compute.internal"
I0708 14:14:59.089874   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:14:59.089890   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:14:59.316209   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612456", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-152-11.eu-west-1.compute.internal"
I0708 14:14:59.544962   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612456", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-22-182.eu-west-1.compute.internal"
I0708 14:15:03.342320   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Node total 217 items received
I0708 14:15:04.091562   60673 drain.go:131] All pods removed from ip-10-180-152-11.eu-west-1.compute.internal
I0708 14:15:04.091561   60673 drain.go:131] All pods removed from ip-10-180-22-182.eu-west-1.compute.internal
I0708 14:15:04.091639   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-22-182.eu-west-1.compute.internal]
I0708 14:15:04.091630   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-152-11.eu-west-1.compute.internal]
I0708 14:15:04.396503   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z3-577bb-795t4 marked with priority 1 successfully
I0708 14:15:04.396527   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z3-577bb-795t4:ip-10-180-152-11.eu-west-1.compute.internal]
I0708 14:15:04.396504   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z1-66665-pnvtr marked with priority 1 successfully
I0708 14:15:04.396562   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z1-66665-pnvtr:ip-10-180-22-182.eu-west-1.compute.internal]
I0708 14:15:04.560195   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z1 size decreased to 1 
I0708 14:15:04.560191   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z3 size decreased to 0 
I0708 14:15:04.560392   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612543", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-152-11.eu-west-1.compute.internal removed
I0708 14:15:04.791942   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612543", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-22-182.eu-west-1.compute.internal removed
I0708 14:15:09.548084   60673 static_autoscaler.go:306] Starting main loop
I0708 14:15:09.548224   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:09.548251   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:09.548719   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:15:09.549039   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:09.549048   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-22-182.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:15:09.549271   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:09.549279   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:09.549503   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:09.549514   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:09.549833   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:09.549900   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:15:09.549909   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:15:09.549917   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:15:09.549921   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:15:09.549925   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:15:09.549937   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:15:09.549950   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:15:09.549964   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:09.549972   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:09.549983   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:15:09.549993   60673 pre_filtering_processor.go:67] Skipping ip-10-180-22-182.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:09.549999   60673 pre_filtering_processor.go:67] Skipping ip-10-180-152-11.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:15:09.550051   60673 klogx.go:87] Node ip-10-180-68-47.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:15:09.550067   60673 cluster.go:156] Simulating node ip-10-180-68-47.eu-west-1.compute.internal removal
I0708 14:15:09.550094   60673 cluster.go:174] node ip-10-180-68-47.eu-west-1.compute.internal may be removed
I0708 14:15:09.550107   60673 nodes.go:84] ip-10-180-68-47.eu-west-1.compute.internal is unneeded since 2024-07-08 14:14:58.620501 +0530 IST m=+589.439708876 duration 10.9274955s
I0708 14:15:09.550142   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:14:58.620501 +0530 IST m=+589.439708876 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:15:09.550161   60673 static_autoscaler.go:655] Starting scale down
I0708 14:15:09.550179   60673 nodes.go:126] ip-10-180-68-47.eu-west-1.compute.internal was unneeded for 10.9274955s
I0708 14:15:09.550200   60673 klogx.go:87] Considering node ip-10-180-68-47.eu-west-1.compute.internal for standard scale down
I0708 14:15:09.782901   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-68-47.eu-west-1.compute.internal
I0708 14:15:09.782933   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-68-47.eu-west-1.compute.internal"
I0708 14:15:09.782983   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-68-47.eu-west-1.compute.internal", UID:"c8097676-ff7f-44c6-b5d0-942d086c219e", APIVersion:"v1", ResourceVersion:"612602", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:15:09.783086   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:15:10.009492   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612543", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-68-47.eu-west-1.compute.internal"
I0708 14:15:12.170031   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:15:12.170160   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 99.625Âµs
I0708 14:15:14.783428   60673 drain.go:131] All pods removed from ip-10-180-68-47.eu-west-1.compute.internal
I0708 14:15:14.783492   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-68-47.eu-west-1.compute.internal]
I0708 14:15:15.059466   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-j6vfg marked with priority 1 successfully
I0708 14:15:15.059488   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z2-55dc4-j6vfg:ip-10-180-68-47.eu-west-1.compute.internal]
I0708 14:15:15.225819   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z2 size decreased to 0 
I0708 14:15:15.226184   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"612613", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-68-47.eu-west-1.compute.internal removed
I0708 14:15:20.238940   60673 static_autoscaler.go:306] Starting main loop
I0708 14:15:20.239007   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:20.239030   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:20.239428   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:15:20.239743   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:20.239753   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:20.239962   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:20.239971   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:20.240178   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:20.240187   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-22-182.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927436Ki
I0708 14:15:20.240462   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:20.240510   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:15:20.240517   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:15:20.240524   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:15:20.240528   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:15:20.240532   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:15:20.240545   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:15:20.240558   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:15:20.240574   60673 pre_filtering_processor.go:67] Skipping ip-10-180-152-11.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:15:20.240582   60673 pre_filtering_processor.go:67] Skipping ip-10-180-68-47.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:15:20.240589   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:20.240597   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:20.240601   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:15:20.240610   60673 pre_filtering_processor.go:67] Skipping ip-10-180-22-182.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:20.240640   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:15:30.942716   60673 static_autoscaler.go:306] Starting main loop
I0708 14:15:30.942788   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:30.942809   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:31.258324   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z3-577bb-795t4 marked with priority 1 successfully
I0708 14:15:31.425956   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z1-66665-pnvtr marked with priority 1 successfully
I0708 14:15:31.426291   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:15:31.426643   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:31.426657   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:15:31.426855   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:31.426864   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:15:31.427054   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:31.427061   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-68-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:15:31.427301   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:31.427358   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:15:31.427394   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:15:31.427401   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:15:31.427408   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:15:31.427413   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:15:31.427416   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:15:31.427429   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:15:31.427442   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:15:31.427457   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:31.427467   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:31.427472   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:15:31.427480   60673 pre_filtering_processor.go:67] Skipping ip-10-180-68-47.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:15:31.427509   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:15:41.885317   60673 static_autoscaler.go:306] Starting main loop
I0708 14:15:41.885427   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:41.885451   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:42.192286   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-j6vfg marked with priority 1 successfully
I0708 14:15:42.192566   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:42.192577   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:42.193226   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:15:42.193759   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:42.193781   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:42.194231   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:42.194251   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:42.194775   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:42.194801   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:15:42.194815   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:15:42.194832   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:15:42.194864   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:15:42.194878   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:15:42.194896   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:15:42.194959   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:15:42.194981   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:15:42.194991   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:15:42.195003   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:15:42.195026   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:15:42.195036   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:15:42.195046   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:15:42.195084   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:15:42.195098   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:15:42.195114   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:15:42.195124   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:15:42.195132   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:15:42.195165   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:15:42.195197   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:15:42.195230   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:15:42.195249   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:42.195260   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:15:42.195322   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:13:01.371068 +0530 IST m=+472.190900418 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:15:52.655042   60673 static_autoscaler.go:306] Starting main loop
I0708 14:15:52.655125   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:52.655150   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:15:52.655461   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:15:52.655764   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:52.655772   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:52.656006   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:52.656015   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:52.656228   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:15:52.656235   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:15:52.656453   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:15:52.656465   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:15:52.656470   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:15:52.656478   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:15:52.656499   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:15:52.656505   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:15:52.656511   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:15:52.656516   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-003f2344fe0a49cbe"
I0708 14:15:52.656519   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-003f2344fe0a49cbe, it's either been removed or it's not managed by this controller
W0708 14:15:52.656524   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-003f2344fe0a49cbe
I0708 14:15:52.656553   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:15:52.656562   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:15:52.656571   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:15:52.656577   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:15:52.656582   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-003f2344fe0a49cbe"
I0708 14:15:52.656586   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-003f2344fe0a49cbe, it's either been removed or it's not managed by this controller
W0708 14:15:52.656589   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-003f2344fe0a49cbe, skipping
I0708 14:15:52.656598   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:15:52.656603   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:15:52.656606   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:15:52.656626   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:15:52.656721   60673 klogx.go:87] failed to find place for default/small-scale-up-pod-59bd8c6bf6-dwhkq: cannot put pod small-scale-up-pod-59bd8c6bf6-dwhkq on any node
I0708 14:15:52.656730   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:15:52.656738   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:15:52.656742   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:15:52.656746   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:15:52.656752   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq is unschedulable
I0708 14:15:52.656764   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:15:52.656847   60673 orchestrator.go:566] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:15:52.657006   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:15:52.657045   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z1-4467435865879638806 and template-node-for-shoot--i585976--ca-test-one-zone-z1-6773657626995086163 are not similar, ephemeral-storage does not match
I0708 14:15:52.657302   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-712522291592954588 and template-node-for-shoot--i585976--ca-test-one-zone-z1-6773657626995086163 are not similar, ephemeral-storage does not match
I0708 14:15:52.657505   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z3-2241239074435600830 and template-node-for-shoot--i585976--ca-test-one-zone-z1-6773657626995086163 are not similar, ephemeral-storage does not match
I0708 14:15:52.657702   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z1 would waste 75.00% CPU, 99.35% Memory, 87.17% Blended
I0708 14:15:52.657722   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 75.00% CPU, 99.35% Memory, 87.17% Blended
I0708 14:15:52.657728   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z3 would waste 75.00% CPU, 99.35% Memory, 87.17% Blended
I0708 14:15:52.657736   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z2
I0708 14:15:52.657744   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-three-zones-z2
I0708 14:15:52.657756   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-712522291592954588 and template-node-for-shoot--i585976--ca-test-one-zone-z1-6773657626995086163 are not similar, ephemeral-storage does not match
I0708 14:15:52.657797   60673 orchestrator.go:212] Found 2 similar node groups: [shoot--i585976--ca-test-three-zones-z1 shoot--i585976--ca-test-three-zones-z3]
I0708 14:15:52.657818   60673 orchestrator.go:247] Splitting scale-up between 3 similar node groups: {shoot--i585976--ca-test-three-zones-z2, shoot--i585976--ca-test-three-zones-z1, shoot--i585976--ca-test-three-zones-z3}
I0708 14:15:52.657831   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:15:52.657843   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1
I0708 14:15:52.657861   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z2 by 1
I0708 14:15:52.824105   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W0708 14:15:52.824150   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:15:52.824226   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"small-scale-up-pod-59bd8c6bf6-dwhkq", UID:"9efe8aec-a2dc-440e-ae7a-5defd39b0347", APIVersion:"v1", ResourceVersion:"612877", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:16:03.280903   60673 static_autoscaler.go:306] Starting main loop
I0708 14:16:03.280964   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:03.280983   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:03.281272   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:16:03.281566   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:03.281574   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:03.281799   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:03.281805   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:03.282002   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:03.282009   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
W0708 14:16:03.282199   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:16:03.282240   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:03.282250   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:03.282255   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:03.282262   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:16:03.282269   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-003f2344fe0a49cbe"
I0708 14:16:03.282273   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-003f2344fe0a49cbe, it's either been removed or it's not managed by this controller
W0708 14:16:03.282279   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-003f2344fe0a49cbe
I0708 14:16:03.282285   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:03.282288   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:03.282307   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:16:03.282338   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:16:03.282347   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:03.282352   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:03.282357   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:16:03.282363   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-003f2344fe0a49cbe"
I0708 14:16:03.282367   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-003f2344fe0a49cbe, it's either been removed or it's not managed by this controller
W0708 14:16:03.282371   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-003f2344fe0a49cbe, skipping
I0708 14:16:03.282376   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:03.282379   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:03.282383   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:16:03.282557   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:16:03.282625   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-3789076991315452132-upcoming-0
I0708 14:16:03.282634   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:16:03.282641   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:16:03.282645   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:16:03.282655   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:16:03.282667   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:16:03.282679   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:16:03.282704   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:16:03.282714   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:03.282719   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:16:03.282755   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:16:13.871907   60673 static_autoscaler.go:306] Starting main loop
I0708 14:16:13.872022   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:13.872051   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:13.872345   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:13.872355   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:13.872653   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:13.872661   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:13.872869   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:16:13.873104   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:13.873114   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:13.873368   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:13.873379   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:13.873384   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:13.873391   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:16:13.873397   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:13.873402   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:13.873407   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:16:13.873445   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:16:13.873453   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:13.873457   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:13.873462   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:16:13.873468   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:13.873472   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:13.873476   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:16:13.873648   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:16:13.873722   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6950108296352996925-upcoming-0
I0708 14:16:13.873731   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:16:13.873737   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:16:13.873742   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:16:13.873745   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:16:13.873758   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:16:13.873770   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:16:13.873786   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:16:13.873796   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:13.873800   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:16:13.873829   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:16:14.855459   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSINode total 19 items received
I0708 14:16:24.338558   60673 static_autoscaler.go:306] Starting main loop
I0708 14:16:24.338660   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:24.338684   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:24.338956   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:16:24.339253   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:24.339262   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:24.339482   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:24.339490   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:24.339688   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:24.339696   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:24.339950   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:24.339963   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:24.339968   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:24.339976   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:16:24.339991   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:24.339995   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:24.340000   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:16:24.340030   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:16:24.340040   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:24.340044   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:24.340049   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:16:24.340059   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:24.340063   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:24.340067   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:16:24.340227   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:16:24.340304   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-3458561791103394060-upcoming-0
I0708 14:16:24.340312   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:16:24.340319   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:16:24.340324   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:16:24.340327   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:16:24.340340   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:16:24.340352   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:16:24.340366   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:16:24.340375   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:24.340379   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:16:24.340409   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:16:35.381548   60673 static_autoscaler.go:306] Starting main loop
I0708 14:16:35.381694   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:35.381741   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:16:35.382171   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:35.382191   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:35.382769   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:16:35.383226   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:35.383238   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:35.383444   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:16:35.383452   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:16:35.383714   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:35.383731   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:35.383737   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:35.383744   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:16:35.383751   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:35.383755   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:35.383760   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:16:35.383790   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:16:35.383805   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:16:35.383809   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:16:35.383814   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:16:35.383820   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:16:35.383824   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:16:35.383828   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:16:35.383972   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:16:35.384044   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-7106209290534617149-upcoming-0
I0708 14:16:35.384052   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:16:35.384059   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:16:35.384064   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:16:35.384068   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:16:35.384081   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:16:35.384094   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:16:35.384108   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:16:35.384117   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:16:35.384121   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:16:35.384149   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:16:39.495449   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Service total 4 items received
I0708 14:18:04.323774   60673 static_autoscaler.go:306] Starting main loop
I0708 14:18:04.323949   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:18:04.324007   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:18:04.324346   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:18:04.324634   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:18:04.324644   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:18:04.324839   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:18:04.324846   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:18:04.325052   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:18:04.325059   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:18:04.325313   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:18:04.325323   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:18:04.325329   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:18:04.325336   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-04e3b436e7df484fb
I0708 14:18:04.325350   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:18:04.325354   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:18:04.325364   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1c/i-0311a5360d6f642ef
I0708 14:18:04.325394   60673 static_autoscaler.go:432] 3 unregistered nodes present
I0708 14:18:04.325403   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-04e3b436e7df484fb"
I0708 14:18:04.325407   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-04e3b436e7df484fb, it's either been removed or it's not managed by this controller
W0708 14:18:04.325412   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-04e3b436e7df484fb, skipping
I0708 14:18:04.325423   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0311a5360d6f642ef"
I0708 14:18:04.325427   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0311a5360d6f642ef, it's either been removed or it's not managed by this controller
W0708 14:18:04.325438   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1c/i-0311a5360d6f642ef, skipping
I0708 14:18:04.325646   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:18:04.325801   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-7842081781572985456-upcoming-0
I0708 14:18:04.325812   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:18:04.325823   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:18:04.325831   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:18:04.325842   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:18:04.325856   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:18:04.325870   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:18:04.325890   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:18:04.325899   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:18:04.325903   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:18:04.325947   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:18:18.439487   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineClass total 12 items received
I0708 14:18:20.536246   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.Machine total 87 items received
I0708 14:18:30.563243   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:18:30.563455   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 151.958Âµs
I0708 14:18:39.329338   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PersistentVolumeClaim total 6 items received
I0708 14:18:39.329338   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PodDisruptionBudget total 0 items received
W0708 14:18:43.130465   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSIStorageCapacity ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130650   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130679   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.DaemonSet ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130708   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSIDriver ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130450   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Pod ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130509   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.ReplicaSet ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130522   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Job ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130530   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSINode ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130545   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.StatefulSet ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130581   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130621   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130618   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.PersistentVolume ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.130572   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0708 14:18:43.130844   60673 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: Get "https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/persistentvolumeclaims?allowWatchBookmarks=true&resourceVersion=610699&timeout=9m38s&timeoutSeconds=578&watch=true": http2: client connection lost
E0708 14:18:43.130903   60673 reflector.go:150] k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: Get "https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/policy/v1/poddisruptionbudgets?allowWatchBookmarks=true&resourceVersion=608168&timeout=9m11s&timeoutSeconds=551&watch=true": http2: client connection lost
W0708 14:18:43.131036   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.StorageClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0708 14:18:43.131144   60673 reflector.go:470] k8s.io/client-go/informers/factory.go:160: watch of *v1.ReplicationController ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0708 14:18:43.131578   60673 status.go:138] Failed to retrieve status configmap for update: Get "https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/configmaps/cluster-autoscaler-status": http2: client connection lost
I0708 14:18:43.131668   60673 metrics.go:477] Function main took 38.809300792s to complete
I0708 14:18:43.941375   60673 reflector.go:332] Listing and watching *v1.ReplicaSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:43.946079   60673 reflector.go:332] Listing and watching *v1.Job from k8s.io/client-go/informers/factory.go:160
I0708 14:18:43.991152   60673 reflector.go:332] Listing and watching *v1.PodDisruptionBudget from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.079838   60673 reflector.go:332] Listing and watching *v1.CSINode from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.138162   60673 reflector.go:332] Listing and watching *v1.Namespace from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.191095   60673 reflector.go:332] Listing and watching *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.288656   60673 reflector.go:332] Listing and watching *v1.Service from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.290998   60673 reflector.go:332] Listing and watching *v1.StatefulSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.304308   60673 reflector.go:332] Listing and watching *v1.ReplicationController from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.320727   60673 reflector.go:332] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.338150   60673 reflector.go:332] Listing and watching *v1.CSIStorageCapacity from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.338900   60673 reflector.go:332] Listing and watching *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.455383   60673 reflector.go:332] Listing and watching *v1.Pod from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.545321   60673 request.go:629] Waited for 89.754083ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/pods?resourceVersion=613514
I0708 14:18:44.545693   60673 reflector.go:332] Listing and watching *v1.DaemonSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.545808   60673 reflector.go:332] Listing and watching *v1.PersistentVolume from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.546098   60673 reflector.go:332] Listing and watching *v1.StorageClass from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.567128   60673 reflector.go:332] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.659772   60673 reflector.go:359] Caches populated for *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.659830   60673 reflector.go:359] Caches populated for *v1.CSINode from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.742441   60673 request.go:629] Waited for 196.558833ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/apps/v1/daemonsets?resourceVersion=613511
I0708 14:18:44.887542   60673 reflector.go:359] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.887542   60673 reflector.go:359] Caches populated for *v1.Namespace from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.887690   60673 reflector.go:359] Caches populated for *v1.Service from k8s.io/client-go/informers/factory.go:160
I0708 14:18:44.942524   60673 request.go:629] Waited for 396.600834ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/persistentvolumes?resourceVersion=609844
I0708 14:18:45.142480   60673 request.go:629] Waited for 596.260208ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/apis/storage.k8s.io/v1/storageclasses?resourceVersion=608822
I0708 14:18:45.335892   60673 reflector.go:359] Caches populated for *v1.Job from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.335892   60673 reflector.go:359] Caches populated for *v1.CSIStorageCapacity from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.336516   60673 reflector.go:359] Caches populated for *v1.StatefulSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.336555   60673 reflector.go:359] Caches populated for *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.336923   60673 reflector.go:359] Caches populated for *v1.ReplicationController from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.337770   60673 reflector.go:359] Caches populated for *v1.ReplicaSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.345130   60673 reflector.go:359] Caches populated for *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.351974   60673 reflector.go:359] Caches populated for *v1.Pod from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.567961   60673 reflector.go:359] Caches populated for *v1.Node from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.574907   60673 reflector.go:359] Caches populated for *v1.PersistentVolume from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.574982   60673 reflector.go:359] Caches populated for *v1.StorageClass from k8s.io/client-go/informers/factory.go:160
I0708 14:18:45.576189   60673 reflector.go:359] Caches populated for *v1.DaemonSet from k8s.io/client-go/informers/factory.go:160
I0708 14:18:53.132859   60673 static_autoscaler.go:306] Starting main loop
I0708 14:18:53.133186   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:18:53.133258   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:18:53.135338   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:18:53.135982   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:18:53.136006   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:18:53.136564   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:18:53.136583   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:18:53.137228   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:18:53.137297   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z2 finished successfully in 1m41.916237708s
I0708 14:18:53.137401   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:18:53.137423   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:18:53.137450   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:18:53.137462   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:18:53.137471   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:18:53.137505   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:18:53.137541   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:18:53.137570   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:18:53.137587   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:18:53.137617   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:18:53.137734   60673 klogx.go:87] Node ip-10-180-80-213.eu-west-1.compute.internal - cpu requested is 49.7917% of allocatable
I0708 14:18:53.137772   60673 cluster.go:156] Simulating node ip-10-180-80-213.eu-west-1.compute.internal removal
I0708 14:18:53.138065   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:18:53.138115   60673 cluster.go:174] node ip-10-180-80-213.eu-west-1.compute.internal may be removed
I0708 14:18:53.138160   60673 nodes.go:84] ip-10-180-80-213.eu-west-1.compute.internal is unneeded since 2024-07-08 14:18:53.132778 +0530 IST m=+745.559203293 duration 0s
I0708 14:18:53.138262   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:18:53.138320   60673 static_autoscaler.go:655] Starting scale down
I0708 14:18:53.138373   60673 nodes.go:134] ip-10-180-80-213.eu-west-1.compute.internal was unneeded for 0s
I0708 14:18:53.138456   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:18:53.138530   60673 taints.go:317] Releasing taint {Key:DeletionCandidateOfClusterAutoscaler Value:1720428192 Effect:PreferNoSchedule TimeAdded:<nil>} on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:18:53.593612   60673 taints.go:352] Successfully released DeletionCandidateOfClusterAutoscaler on node ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:18:53.831432   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-80-213.eu-west-1.compute.internal
I0708 14:19:04.342490   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:04.342782   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:04.342847   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:04.343791   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:19:04.344893   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:04.345652   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:04.345679   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:04.346249   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:04.346283   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:04.346995   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:04.347177   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:04.347195   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:04.347208   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:04.347215   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:04.347220   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:19:04.347237   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:19:04.347252   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:19:04.347278   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:19:04.347290   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:04.347295   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:19:04.347403   60673 klogx.go:87] Node ip-10-180-80-213.eu-west-1.compute.internal - cpu requested is 49.7917% of allocatable
I0708 14:19:04.347437   60673 cluster.go:156] Simulating node ip-10-180-80-213.eu-west-1.compute.internal removal
I0708 14:19:04.347626   60673 klogx.go:87] Pod default/small-scale-up-pod-59bd8c6bf6-dwhkq can be moved to ip-10-180-29-171.eu-west-1.compute.internal
I0708 14:19:04.347653   60673 cluster.go:174] node ip-10-180-80-213.eu-west-1.compute.internal may be removed
I0708 14:19:04.347679   60673 nodes.go:84] ip-10-180-80-213.eu-west-1.compute.internal is unneeded since 2024-07-08 14:18:53.132778 +0530 IST m=+745.559203293 duration 11.20965275s
I0708 14:19:04.347735   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:15:09.548055 +0530 IST m=+600.367204376 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:19:04.347764   60673 static_autoscaler.go:655] Starting scale down
I0708 14:19:04.347802   60673 nodes.go:134] ip-10-180-80-213.eu-west-1.compute.internal was unneeded for 11.20965275s
I0708 14:19:04.347836   60673 klogx.go:87] Considering node ip-10-180-80-213.eu-west-1.compute.internal for standard scale down
I0708 14:19:04.802630   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-80-213.eu-west-1.compute.internal
I0708 14:19:04.802790   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-80-213.eu-west-1.compute.internal", UID:"fbb208dd-d462-44c4-b9c8-36acab4669b6", APIVersion:"v1", ResourceVersion:"614281", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:19:04.802859   60673 actuator.go:215] Scale-down: removing node ip-10-180-80-213.eu-west-1.compute.internal, utilization: {0.4979166666666667 0.09747533815043839 0 cpu 0.4979166666666667}, pods to reschedule: small-scale-up-pod-59bd8c6bf6-dwhkq
I0708 14:19:04.802971   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:19:05.037940   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"614283", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' Scale-down: removing node ip-10-180-80-213.eu-west-1.compute.internal, utilization: {0.4979166666666667 0.09747533815043839 0 cpu 0.4979166666666667}, pods to reschedule: small-scale-up-pod-59bd8c6bf6-dwhkq
I0708 14:19:09.805391   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"node-exporter-dlh8l", UID:"4d849d73-b49d-4693-bca7-b28f9370ad3c", APIVersion:"v1", ResourceVersion:"613757", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:10.005063   60673 request.go:629] Waited for 199.30925ms due to client-side throttling, not priority and fairness, request: POST:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/pods/csi-driver-node-654rn/eviction
I0708 14:19:10.037800   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-proxy-three-zones-v1.29.4-csc54", UID:"f1c1af78-81ff-4e00-bbef-22c665564cda", APIVersion:"v1", ResourceVersion:"613753", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:10.205443   60673 request.go:629] Waited for 399.638041ms due to client-side throttling, not priority and fairness, request: POST:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/pods/node-problem-detector-wjp8g/eviction
I0708 14:19:10.405836   60673 request.go:629] Waited for 367.764208ms due to client-side throttling, not priority and fairness, request: POST:https://api.ca-test.i585976.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/events
I0708 14:19:11.276140   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"small-scale-up-pod-59bd8c6bf6-dwhkq", UID:"9efe8aec-a2dc-440e-ae7a-5defd39b0347", APIVersion:"v1", ResourceVersion:"613891", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:11.282058   60673 drain.go:143] Not deleted yet default/small-scale-up-pod-59bd8c6bf6-dwhkq
I0708 14:19:11.507302   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"node-problem-detector-wjp8g", UID:"bb0aec4d-6ff7-404a-ac7e-6e28cd29b503", APIVersion:"v1", ResourceVersion:"613909", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:11.739849   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"network-problem-detector-pod-jtq29", UID:"98b90fbb-ba3b-4423-bc4e-0d3986746439", APIVersion:"v1", ResourceVersion:"613791", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:11.972443   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"egress-filter-applier-k6jmc", UID:"28fed521-5c55-44cc-b566-abe1108a5ff9", APIVersion:"v1", ResourceVersion:"613706", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:12.204443   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"csi-driver-node-654rn", UID:"7d3cefc5-9ede-4f05-bd21-d536d80afbbf", APIVersion:"v1", ResourceVersion:"613803", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:12.435155   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"network-problem-detector-host-8mkjf", UID:"eb173cdd-25e4-4a89-a960-6d0d2e203a3a", APIVersion:"v1", ResourceVersion:"613669", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:12.667420   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"apiserver-proxy-lcqqf", UID:"69002b92-08be-48de-8a18-cfc73dae92cf", APIVersion:"v1", ResourceVersion:"613799", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:12.900167   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"calico-node-tbqr5", UID:"9184030c-59be-43bc-a60f-2ff8a1d619ef", APIVersion:"v1", ResourceVersion:"613850", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:13.130283   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"node-local-dns-p2frb", UID:"dcb33005-c303-4aa0-8d6c-22260e01c5cc", APIVersion:"v1", ResourceVersion:"613821", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' deleting pod for node scale down
I0708 14:19:15.269355   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:15.269540   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:15.269581   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:15.270254   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:19:15.270265   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:19:15.270850   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:15.271154   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:15.271165   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-213.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:19:15.271369   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:15.271377   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-213.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:19:15.271675   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:15.272144   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:15.272165   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:15.272178   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:15.272185   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:15.272189   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:19:15.272206   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:19:15.272218   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:19:15.272238   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:15.272247   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:19:15.272264   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:19:15.272326   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:19:15.272359   60673 static_autoscaler.go:655] Starting scale down
I0708 14:19:15.272398   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:16.513583   60673 drain.go:131] All pods removed from ip-10-180-80-213.eu-west-1.compute.internal
I0708 14:19:16.513781   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-80-213.eu-west-1.compute.internal]
I0708 14:19:16.819992   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-jnzbm marked with priority 1 successfully
I0708 14:19:16.820006   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z2-55dc4-jnzbm:ip-10-180-80-213.eu-west-1.compute.internal]
I0708 14:19:16.984591   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z2 size decreased to 0 
I0708 14:19:16.984685   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"614596", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' Scale-down: node ip-10-180-80-213.eu-west-1.compute.internal removed with drain
I0708 14:19:25.740861   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:25.741135   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:25.741204   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:25.742136   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:19:25.742157   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:19:25.743238   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:25.743960   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:25.743985   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:25.744478   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:25.744499   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:25.745059   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:25.745176   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:25.745200   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:25.745219   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:25.745230   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:25.745239   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:19:25.745273   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:19:25.745305   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:19:25.745347   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:19:25.745372   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:25.745385   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:19:25.745408   60673 pre_filtering_processor.go:67] Skipping ip-10-180-80-213.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:19:25.745486   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:19:36.244305   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:36.244607   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:36.244670   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:36.245664   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:36.246428   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:36.246454   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-213.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:19:36.246985   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:36.247007   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:36.247487   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:36.247507   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-213.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:19:36.248142   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:36.248252   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:36.248274   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:36.248333   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:36.248357   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:36.248368   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:19:36.248403   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:19:36.248437   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:19:36.248491   60673 pre_filtering_processor.go:67] Skipping ip-10-180-80-213.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:19:36.248516   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:19:36.248535   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:36.248546   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:19:36.248626   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:19:46.780280   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:46.780467   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:46.780514   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:46.950204   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-jnzbm marked with priority 1 successfully
I0708 14:19:46.950915   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:46.951630   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:46.951655   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:46.952192   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:46.952214   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:46.952721   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:46.952739   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:46.953298   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:46.953418   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:19:46.953511   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:46.953732   60673 klogx.go:87] failed to find place for default/volume-pod-8f7cf894d-n596f: error running pre filter plugins for pod volume-pod-8f7cf894d-n596f; pod has unbound immediate PersistentVolumeClaims
I0708 14:19:46.953769   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:46.953823   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:46.953840   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:46.953851   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:19:46.953887   60673 static_autoscaler.go:578] Unschedulable pods are very new, waiting one iteration for more
I0708 14:19:46.953921   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:19:46.953972   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:19:46.953996   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:46.954008   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:19:46.954089   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:15:52.654954 +0530 IST m=+643.473874085 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=true scaleDownInCooldown=true
I0708 14:19:57.420344   60673 static_autoscaler.go:306] Starting main loop
I0708 14:19:57.420480   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:57.420510   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:19:57.420875   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:57.420889   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:57.421179   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:57.421189   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:57.421439   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:19:57.421448   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:19:57.421669   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:19:57.421977   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:19:57.421989   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-02885fc1e875e2aff"
I0708 14:19:57.421996   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-02885fc1e875e2aff, it's either been removed or it's not managed by this controller
W0708 14:19:57.422005   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-02885fc1e875e2aff
I0708 14:19:57.422037   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:19:57.422046   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-02885fc1e875e2aff"
I0708 14:19:57.422051   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-02885fc1e875e2aff, it's either been removed or it's not managed by this controller
W0708 14:19:57.422057   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-02885fc1e875e2aff, skipping
I0708 14:19:57.422082   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:19:57.422182   60673 klogx.go:87] failed to find place for default/volume-pod-8f7cf894d-n596f: cannot put pod volume-pod-8f7cf894d-n596f on any node
I0708 14:19:57.422211   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:19:57.422235   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:19:57.422245   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:19:57.422254   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:19:57.422268   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f is unschedulable
I0708 14:19:57.422316   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:19:57.422632   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-one-zone-z1-5143855657555337439" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-one-zone-z1-5143855657555337439\" not found"
I0708 14:19:57.422767   60673 binder.go:889] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i585976--ca-test-74f19f13-84f4-498f-8d98-f55bd7ec1b19" node="template-node-for-shoot--i585976--ca-test-one-zone-z1-5143855657555337439" pod="default/volume-pod-8f7cf894d-n596f" err="no matching NodeSelectorTerms"
I0708 14:19:57.422827   60673 orchestrator.go:566] Pod default/volume-pod-8f7cf894d-n596f can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I0708 14:19:57.422985   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z1-537143777659731927" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z1-537143777659731927\" not found"
I0708 14:19:57.423021   60673 binder.go:889] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i585976--ca-test-74f19f13-84f4-498f-8d98-f55bd7ec1b19" node="template-node-for-shoot--i585976--ca-test-three-zones-z1-537143777659731927" pod="default/volume-pod-8f7cf894d-n596f" err="no matching NodeSelectorTerms"
I0708 14:19:57.423042   60673 orchestrator.go:566] Pod default/volume-pod-8f7cf894d-n596f can't be scheduled on shoot--i585976--ca-test-three-zones-z1, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I0708 14:19:57.423182   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338\" not found"
I0708 14:19:57.423217   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338"
I0708 14:19:57.423375   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z3-3508974097683451341" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z3-3508974097683451341\" not found"
I0708 14:19:57.423408   60673 binder.go:889] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i585976--ca-test-74f19f13-84f4-498f-8d98-f55bd7ec1b19" node="template-node-for-shoot--i585976--ca-test-three-zones-z3-3508974097683451341" pod="default/volume-pod-8f7cf894d-n596f" err="no matching NodeSelectorTerms"
I0708 14:19:57.423429   60673 orchestrator.go:566] Pod default/volume-pod-8f7cf894d-n596f can't be scheduled on shoot--i585976--ca-test-three-zones-z3, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I0708 14:19:57.423447   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:19:57.423458   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z1
I0708 14:19:57.423586   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5143855657555337439 are not similar, ephemeral-storage does not match
I0708 14:19:57.424106   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338-e-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338-e-0\" not found"
I0708 14:19:57.424156   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338-e-0"
I0708 14:19:57.424202   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z3
I0708 14:19:57.424224   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-three-zones-z2 would waste 50.00% CPU, 99.35% Memory, 74.67% Blended
I0708 14:19:57.424253   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-three-zones-z2
I0708 14:19:57.424270   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-three-zones-z2
I0708 14:19:57.424350   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-three-zones-z2-4522715224306930338 and template-node-for-shoot--i585976--ca-test-one-zone-z1-5143855657555337439 are not similar, ephemeral-storage does not match
I0708 14:19:57.424411   60673 orchestrator.go:215] No similar node groups found
I0708 14:19:57.424451   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:19:57.424477   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1
I0708 14:19:57.424510   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-three-zones-z2 by 1
I0708 14:19:57.424807   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"614834", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-three-zones-z2 size to 1 instead of 0 (max: 1)
I0708 14:19:57.592185   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W0708 14:19:57.592283   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:19:57.656641   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"614834", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-three-zones-z2 size set to 1 instead of 0 (max: 1)
I0708 14:19:57.889143   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"volume-pod-8f7cf894d-n596f", UID:"4ef46c49-a3e3-4518-a9ac-79771c89c363", APIVersion:"v1", ResourceVersion:"614868", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-three-zones-z2 0->1 (max: 1)}]
I0708 14:20:08.057710   60673 static_autoscaler.go:306] Starting main loop
I0708 14:20:08.057923   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:08.058112   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:08.058866   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:20:08.059693   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:08.059717   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:08.060284   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:08.060303   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:08.060909   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:08.060928   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
W0708 14:20:08.061474   60673 clusterstate.go:492] Failed to find readiness information for shoot--i585976--ca-test-three-zones-z2
I0708 14:20:08.061561   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:08.061587   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-02885fc1e875e2aff"
I0708 14:20:08.061600   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-02885fc1e875e2aff, it's either been removed or it's not managed by this controller
W0708 14:20:08.061619   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1a/i-02885fc1e875e2aff
I0708 14:20:08.061691   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:20:08.061715   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-02885fc1e875e2aff"
I0708 14:20:08.061728   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-02885fc1e875e2aff, it's either been removed or it's not managed by this controller
W0708 14:20:08.061741   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1a/i-02885fc1e875e2aff, skipping
I0708 14:20:08.062154   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:20:08.062390   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-2180685001534057670-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-2180685001534057670-upcoming-0\" not found"
I0708 14:20:08.062452   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-2180685001534057670-upcoming-0"
I0708 14:20:08.062488   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-2180685001534057670-upcoming-0
I0708 14:20:08.062509   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:20:08.062528   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:20:08.062541   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:20:08.062549   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:20:08.062584   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:20:08.062619   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:20:08.062659   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:20:08.062687   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:08.062699   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:20:08.062774   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:20:08.525000   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Deployment total 32 items received
I0708 14:20:18.759126   60673 static_autoscaler.go:306] Starting main loop
I0708 14:20:18.759478   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:18.759552   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:18.760355   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:20:18.761165   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:18.761190   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:18.761894   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:18.761917   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:18.762550   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:18.762575   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:18.763401   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:18.763514   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:20:18.763948   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:20:18.764197   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4329970504552549280-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-4329970504552549280-upcoming-0\" not found"
I0708 14:20:18.764260   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4329970504552549280-upcoming-0"
I0708 14:20:18.764290   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4329970504552549280-upcoming-0
I0708 14:20:18.764317   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:20:18.764335   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:20:18.764349   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:20:18.764358   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:20:18.764393   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:20:18.764431   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:20:18.764470   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:20:18.764490   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:18.764501   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:20:18.764575   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:20:29.243256   60673 static_autoscaler.go:306] Starting main loop
I0708 14:20:29.243564   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:29.243622   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:29.244407   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:20:29.245171   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:29.245197   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:29.245800   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:29.245820   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:29.246476   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:29.246499   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:29.247263   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:29.247368   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:20:29.247793   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:20:29.248054   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-5434902198116350689-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-5434902198116350689-upcoming-0\" not found"
I0708 14:20:29.248116   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-5434902198116350689-upcoming-0"
I0708 14:20:29.248148   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-5434902198116350689-upcoming-0
I0708 14:20:29.248168   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:20:29.248187   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:20:29.248200   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:20:29.248209   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:20:29.248243   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:20:29.248275   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:20:29.248330   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:20:29.248358   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:29.248370   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:20:29.248446   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:20:30.564519   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:20:30.564809   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 217.916Âµs
I0708 14:20:39.716118   60673 static_autoscaler.go:306] Starting main loop
I0708 14:20:39.716334   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:39.716396   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:39.717142   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:39.717170   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:39.717966   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:39.717988   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:39.718604   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:20:39.719212   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:39.719232   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:39.719873   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:39.719994   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:20:39.720425   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:20:39.720685   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-8096758144416003095-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-8096758144416003095-upcoming-0\" not found"
I0708 14:20:39.720748   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-8096758144416003095-upcoming-0"
I0708 14:20:39.720777   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-8096758144416003095-upcoming-0
I0708 14:20:39.720799   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:20:39.720816   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:20:39.720828   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:20:39.720837   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:20:39.720872   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:20:39.720909   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:20:39.720941   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:39.720957   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:20:39.720982   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:20:39.721065   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:20:50.420236   60673 static_autoscaler.go:306] Starting main loop
I0708 14:20:50.420448   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:50.420518   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:20:50.421281   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:50.421309   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:50.422037   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:50.422059   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:50.422678   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:20:50.423240   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:20:50.423262   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:20:50.423997   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:50.424119   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:20:50.424529   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:20:50.424770   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4206703420545011015-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-4206703420545011015-upcoming-0\" not found"
I0708 14:20:50.424833   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-4206703420545011015-upcoming-0"
I0708 14:20:50.424861   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-4206703420545011015-upcoming-0
I0708 14:20:50.424883   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:20:50.424903   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:20:50.424915   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:20:50.424924   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:20:50.424959   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:20:50.424991   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:20:50.425031   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:20:50.425060   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:20:50.425074   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:20:50.425150   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:21:00.916119   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:00.916423   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:00.916489   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:00.917478   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:00.917507   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:00.918373   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:00.918413   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:00.919051   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:00.919075   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:00.919659   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:00.920439   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:00.920929   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:00.921201   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-2852873897467637594-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-2852873897467637594-upcoming-0\" not found"
I0708 14:21:00.921263   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-2852873897467637594-upcoming-0"
I0708 14:21:00.921293   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-2852873897467637594-upcoming-0
I0708 14:21:00.921314   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:21:00.921333   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:21:00.921345   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:00.921354   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:00.921390   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:00.921423   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:00.921472   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:00.921494   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:00.921507   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:00.921584   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:21:11.465977   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:11.466135   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:11.466182   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:11.466847   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:11.466873   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:11.467467   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:11.467488   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:11.467996   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:11.468017   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:11.468503   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:11.469097   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:11.469614   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:11.469820   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-6080672258475329875-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-6080672258475329875-upcoming-0\" not found"
I0708 14:21:11.469876   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-6080672258475329875-upcoming-0"
I0708 14:21:11.469900   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6080672258475329875-upcoming-0
I0708 14:21:11.469920   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:21:11.469937   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:21:11.469948   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:11.469957   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:11.469991   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:11.470023   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:11.470066   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:11.470088   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:11.470099   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:11.470162   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:21:21.983434   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:21.983730   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:21.983798   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:21.984702   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:21.984730   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:21.985523   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:21.985545   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:21.986113   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:21.986651   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:21.986672   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:21.987321   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:21.987848   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:21.988111   60673 binder.go:869] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-6573948486824570354-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i585976--ca-test-three-zones-z2-6573948486824570354-upcoming-0\" not found"
I0708 14:21:21.988175   60673 binder.go:895] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-8f7cf894d-n596f" node="template-node-for-shoot--i585976--ca-test-three-zones-z2-6573948486824570354-upcoming-0"
I0708 14:21:21.988205   60673 klogx.go:87] Pod default/volume-pod-8f7cf894d-n596f can be moved to template-node-for-shoot--i585976--ca-test-three-zones-z2-6573948486824570354-upcoming-0
I0708 14:21:21.988227   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:21:21.988245   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:21:21.988258   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:21.988267   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:21.988301   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:21.988338   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:21.988375   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:21.988399   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:21.988410   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:21.988485   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:21:32.463522   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:32.463786   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:32.463849   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:32.463890   60673 taints.go:442] Overriding status of node ip-10-180-80-172.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:21:32.464827   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:32.465576   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:32.465602   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:32.466224   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:32.466246   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:32.466735   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:32.466753   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:32.467472   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:32.467944   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:32.467966   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:21:32.467985   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:21:32.467997   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:32.468005   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:32.468040   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:32.468074   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:32.468114   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:32.468137   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:32.468148   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:32.468227   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:21:42.941050   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:42.941317   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:42.941379   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:42.942220   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:42.942249   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-172.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841428Ki
I0708 14:21:42.942977   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:42.942999   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:42.943539   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:42.944067   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:42.944087   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:42.944769   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:42.944821   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-three-zones-z2 finished successfully in 1m45.348806333s
I0708 14:21:42.944921   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:42.944945   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:21:42.944964   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:21:42.944975   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:42.944984   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:42.945020   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:42.945059   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:42.945098   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:42.945119   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:42.945130   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:42.945251   60673 klogx.go:87] Node ip-10-180-80-172.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:21:42.945305   60673 cluster.go:156] Simulating node ip-10-180-80-172.eu-west-1.compute.internal removal
I0708 14:21:42.945364   60673 cluster.go:174] node ip-10-180-80-172.eu-west-1.compute.internal may be removed
I0708 14:21:42.945399   60673 nodes.go:84] ip-10-180-80-172.eu-west-1.compute.internal is unneeded since 2024-07-08 14:21:42.940971 +0530 IST m=+915.367253626 duration 0s
I0708 14:21:42.945474   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:21:42.945533   60673 static_autoscaler.go:655] Starting scale down
I0708 14:21:42.945580   60673 nodes.go:126] ip-10-180-80-172.eu-west-1.compute.internal was unneeded for 0s
I0708 14:21:42.945679   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:43.182375   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-80-172.eu-west-1.compute.internal
I0708 14:21:53.650128   60673 static_autoscaler.go:306] Starting main loop
I0708 14:21:53.650379   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:53.650452   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:21:53.651339   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:21:53.652107   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:53.652130   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-80-172.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841428Ki
I0708 14:21:53.652684   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:53.652705   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:53.653276   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:21:53.653296   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:21:53.653913   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:53.654033   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:21:53.654055   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:21:53.654075   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:21:53.654087   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:21:53.654096   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:21:53.654130   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:21:53.654162   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:21:53.654201   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:21:53.654223   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:21:53.654234   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:21:53.654358   60673 klogx.go:87] Node ip-10-180-80-172.eu-west-1.compute.internal - cpu requested is 23.75% of allocatable
I0708 14:21:53.654404   60673 cluster.go:156] Simulating node ip-10-180-80-172.eu-west-1.compute.internal removal
I0708 14:21:53.654474   60673 cluster.go:174] node ip-10-180-80-172.eu-west-1.compute.internal may be removed
I0708 14:21:53.654514   60673 nodes.go:84] ip-10-180-80-172.eu-west-1.compute.internal is unneeded since 2024-07-08 14:21:42.940971 +0530 IST m=+915.367253626 duration 10.709062792s
I0708 14:21:53.654606   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:19:04.34241 +0530 IST m=+756.768856043 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:21:53.654666   60673 static_autoscaler.go:655] Starting scale down
I0708 14:21:53.654714   60673 nodes.go:126] ip-10-180-80-172.eu-west-1.compute.internal was unneeded for 10.709062792s
I0708 14:21:53.654771   60673 klogx.go:87] Considering node ip-10-180-80-172.eu-west-1.compute.internal for standard scale down
I0708 14:21:54.170653   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-80-172.eu-west-1.compute.internal
I0708 14:21:54.170737   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-80-172.eu-west-1.compute.internal"
I0708 14:21:54.170841   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-80-172.eu-west-1.compute.internal", UID:"b5e43890-327d-4c3d-8fc4-46298fc4c709", APIVersion:"v1", ResourceVersion:"615730", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:21:54.171148   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:21:54.478256   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"615733", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-80-172.eu-west-1.compute.internal"
I0708 14:21:59.172048   60673 drain.go:131] All pods removed from ip-10-180-80-172.eu-west-1.compute.internal
I0708 14:21:59.172348   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-80-172.eu-west-1.compute.internal]
I0708 14:21:59.339911   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-st9z9 marked with priority 1 successfully
I0708 14:21:59.339955   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-three-zones-z2-55dc4-st9z9:ip-10-180-80-172.eu-west-1.compute.internal]
I0708 14:21:59.501885   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-three-zones-z2 size decreased to 0 
I0708 14:21:59.502356   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"615801", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-80-172.eu-west-1.compute.internal removed
I0708 14:22:04.785855   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:04.786086   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:04.786143   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:04.787006   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:04.787921   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:04.787952   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:04.788496   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:04.788517   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:04.789034   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:04.789055   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:04.789664   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:04.789773   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:04.789799   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:22:04.789818   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:22:04.789830   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:04.789839   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:22:04.789873   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:22:04.789906   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:22:04.789949   60673 pre_filtering_processor.go:67] Skipping ip-10-180-80-172.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:22:04.789972   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:22:04.789990   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:04.790001   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:22:04.790083   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:22:15.257176   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:15.257484   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:15.257553   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:15.258495   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:15.258524   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:15.259335   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:15.259887   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:15.259910   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:15.260476   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:15.260498   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:15.261130   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:15.261248   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:15.261272   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:22:15.261297   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:22:15.261309   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:15.261318   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:22:15.261353   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:22:15.261386   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:22:15.261425   60673 pre_filtering_processor.go:67] Skipping ip-10-180-80-172.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:22:15.261446   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:22:15.261466   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:15.261478   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:22:15.261558   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:22:25.730525   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:25.730797   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:25.730862   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:25.897706   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-three-zones-z2-55dc4-st9z9 marked with priority 1 successfully
I0708 14:22:25.898444   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:25.899294   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:25.899319   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:25.899873   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:25.899895   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:25.900421   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:25.900440   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:25.901033   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:25.901137   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:22:25.901217   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:25.901239   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:22:25.901258   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:22:25.901270   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:25.901279   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:22:25.901313   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:22:25.901354   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:22:25.901395   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:22:25.901418   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:25.901429   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:22:25.901509   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:22:30.565148   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:22:30.565392   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 148Âµs
I0708 14:22:36.368305   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:36.368636   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:36.368717   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:36.369503   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:36.370282   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:36.370336   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:36.370918   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:36.370939   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:36.371536   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:36.371558   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:36.372153   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:36.372260   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:36.372448   60673 klogx.go:87] failed to find place for default/large-scale-up-pod-79f9b85cdb-tjk7s: cannot put pod large-scale-up-pod-79f9b85cdb-tjk7s on any node
I0708 14:22:36.372476   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:22:36.372530   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:22:36.372552   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:36.372563   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:22:36.372599   60673 klogx.go:87] Pod default/large-scale-up-pod-79f9b85cdb-tjk7s is unschedulable
I0708 14:22:36.372642   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:22:36.372883   60673 orchestrator.go:566] Pod default/large-scale-up-pod-79f9b85cdb-tjk7s can't be scheduled on shoot--i585976--ca-test-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:22:36.373033   60673 orchestrator.go:566] Pod default/large-scale-up-pod-79f9b85cdb-tjk7s can't be scheduled on shoot--i585976--ca-test-three-zones-z1, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I0708 14:22:36.373161   60673 orchestrator.go:566] Pod default/large-scale-up-pod-79f9b85cdb-tjk7s can't be scheduled on shoot--i585976--ca-test-three-zones-z2, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I0708 14:22:36.373292   60673 orchestrator.go:566] Pod default/large-scale-up-pod-79f9b85cdb-tjk7s can't be scheduled on shoot--i585976--ca-test-three-zones-z3, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I0708 14:22:36.373314   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-one-zone-z1
I0708 14:22:36.373329   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z1
I0708 14:22:36.373336   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z2
I0708 14:22:36.373342   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z3
I0708 14:22:36.373370   60673 orchestrator.go:167] No expansion options
I0708 14:22:36.373456   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:22:36.373498   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:22:36.373519   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:36.373531   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:22:36.373555   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"large-scale-up-pod-79f9b85cdb-tjk7s", UID:"c9458551-c471-49e5-99c3-28458e04d31b", APIVersion:"v1", ResourceVersion:"616025", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 Insufficient cpu
I0708 14:22:36.373637   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:19:57.420312 +0530 IST m=+809.846723835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:22:46.842659   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:46.842846   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:46.842912   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:46.843835   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:46.844587   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:46.844611   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:46.845220   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:46.845242   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:46.845787   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:46.845809   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:46.846513   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:46.846627   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:46.846833   60673 klogx.go:87] failed to find place for default/scale-up-pod-a-78d7977858-b4v7w: cannot put pod scale-up-pod-a-78d7977858-b4v7w on any node
I0708 14:22:46.846858   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:22:46.846878   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:22:46.846890   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:46.846914   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:22:46.846934   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w is unschedulable
I0708 14:22:46.846970   60673 orchestrator.go:111] Upcoming 0 nodes
I0708 14:22:46.847312   60673 orchestrator.go:566] Pod default/scale-up-pod-a-78d7977858-b4v7w can't be scheduled on shoot--i585976--ca-test-three-zones-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:22:46.847438   60673 orchestrator.go:566] Pod default/scale-up-pod-a-78d7977858-b4v7w can't be scheduled on shoot--i585976--ca-test-three-zones-z2, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:22:46.847559   60673 orchestrator.go:566] Pod default/scale-up-pod-a-78d7977858-b4v7w can't be scheduled on shoot--i585976--ca-test-three-zones-z3, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:22:46.847611   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z1-4633438138207919178 are not similar, ephemeral-storage does not match
I0708 14:22:46.847652   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z2-6753153527666744021 are not similar, ephemeral-storage does not match
I0708 14:22:46.847676   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z3-8505458878119783499 are not similar, ephemeral-storage does not match
I0708 14:22:46.848249   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z1
I0708 14:22:46.848275   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z2
I0708 14:22:46.848284   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z3
I0708 14:22:46.848306   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-one-zone-z1 would waste 50.00% CPU, 98.17% Memory, 74.08% Blended
I0708 14:22:46.848348   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-one-zone-z1
I0708 14:22:46.848377   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-one-zone-z1
I0708 14:22:46.848417   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z1-4633438138207919178 are not similar, ephemeral-storage does not match
I0708 14:22:46.848448   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z2-6753153527666744021 are not similar, ephemeral-storage does not match
I0708 14:22:46.848472   60673 compare_nodegroups.go:164] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-4446995790156139370 and template-node-for-shoot--i585976--ca-test-three-zones-z3-8505458878119783499 are not similar, ephemeral-storage does not match
I0708 14:22:46.848505   60673 orchestrator.go:215] No similar node groups found
I0708 14:22:46.848555   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-one-zone-z1 0->1 (max: 2)}]
I0708 14:22:46.848582   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-one-zone-z1 size to 1
I0708 14:22:46.848613   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-one-zone-z1 by 1
I0708 14:22:46.848695   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"616088", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-one-zone-z1 size to 1 instead of 0 (max: 2)
I0708 14:22:47.015599   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I0708 14:22:47.079101   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"616088", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i585976--ca-test-one-zone-z1 size set to 1 instead of 0 (max: 2)
I0708 14:22:47.310295   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-a-78d7977858-b4v7w", UID:"7923a843-df94-4838-b6a5-f07410896109", APIVersion:"v1", ResourceVersion:"616098", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-one-zone-z1 0->1 (max: 2)}]
I0708 14:22:57.481902   60673 static_autoscaler.go:306] Starting main loop
I0708 14:22:57.482243   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:57.482313   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:22:57.483057   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:22:57.483835   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:57.483860   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:57.484419   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:57.484444   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:57.485042   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:22:57.485065   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:22:57.485783   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:57.485884   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:22:57.486328   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:22:57.486504   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-2771627984049289693-upcoming-0
I0708 14:22:57.486529   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:22:57.486548   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:22:57.486560   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:22:57.486569   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:22:57.486603   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:22:57.486635   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:22:57.486682   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:22:57.486702   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:22:57.486714   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:22:57.486787   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:07.955981   60673 static_autoscaler.go:306] Starting main loop
I0708 14:23:07.956266   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:07.956334   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:07.957106   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:23:07.957911   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:07.957938   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:07.958676   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:07.958703   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:07.959207   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:07.959232   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:07.959925   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:07.960029   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:23:07.960474   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:23:07.960683   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-4922099729420935251-upcoming-0
I0708 14:23:07.960708   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:23:07.960726   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:23:07.960739   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:23:07.960747   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:23:07.960781   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:23:07.960813   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:23:07.960874   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:23:07.960901   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:07.960912   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:23:07.960987   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:18.514775   60673 static_autoscaler.go:306] Starting main loop
I0708 14:23:18.515050   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:18.515125   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:18.515894   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:18.515920   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:18.516665   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:18.516693   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:18.517330   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:18.517352   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:18.517866   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:23:18.518562   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:18.518664   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:23:18.519104   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:23:18.519290   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-7368116842762252654-upcoming-0
I0708 14:23:18.519313   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:23:18.519371   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:23:18.519393   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:23:18.519403   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:23:18.519439   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:23:18.519472   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:23:18.519521   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:23:18.519551   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:18.519563   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:23:18.519643   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:29.025166   60673 static_autoscaler.go:306] Starting main loop
I0708 14:23:29.025345   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:29.025421   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:29.026183   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:23:29.026982   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:29.027008   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:29.027531   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:29.027546   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:29.028061   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:29.028080   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:29.028796   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:29.028893   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:23:29.029313   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:23:29.029520   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-4293487191506758113-upcoming-0
I0708 14:23:29.029546   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:23:29.029564   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:23:29.029577   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:23:29.029585   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:23:29.029619   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:23:29.029651   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:23:29.029689   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:23:29.029709   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:29.029720   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:23:29.029795   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:39.578240   60673 static_autoscaler.go:306] Starting main loop
I0708 14:23:39.578542   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:39.578609   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:39.579365   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:39.579392   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:39.580218   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:39.580255   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:39.580782   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:23:39.581355   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:39.581375   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:39.582065   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:39.582167   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:23:39.582612   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:23:39.582816   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-2739216906617835047-upcoming-0
I0708 14:23:39.582841   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:23:39.582858   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:23:39.582871   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:23:39.582881   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:23:39.582925   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:23:39.582957   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:23:39.583016   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:23:39.583043   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:39.583055   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:23:39.583147   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:47.108266   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineSet total 45 items received
I0708 14:23:50.048452   60673 static_autoscaler.go:306] Starting main loop
I0708 14:23:50.048762   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:50.048839   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:23:50.049571   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:23:50.050366   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:50.050392   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:50.050940   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:50.050962   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:50.051497   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:23:50.051519   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:23:50.052156   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
W0708 14:23:50.052176   60673 mcm_cloud_provider.go:155] Node ip-10-180-25-116.eu-west-1.compute.internal has no providerId
I0708 14:23:50.052497   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:23:50.052656   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-4658173109548284439-upcoming-0
I0708 14:23:50.052670   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:23:50.052681   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:23:50.052689   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:23:50.052694   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:23:50.052712   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:23:50.052728   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:23:50.052747   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:23:50.052759   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
W0708 14:23:50.052763   60673 mcm_cloud_provider.go:155] Node ip-10-180-25-116.eu-west-1.compute.internal has no providerId
I0708 14:23:50.052769   60673 pre_filtering_processor.go:57] Node ip-10-180-25-116.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:23:50.052782   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:23:50.052835   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:23:52.178920   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineDeployment total 46 items received
I0708 14:24:01.001627   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:01.001900   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:01.001955   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:01.002835   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:01.002862   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:01.003673   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:01.003700   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:01.004238   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:01.004255   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:01.004773   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:01.004794   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:01.005448   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:01.005985   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:01.006186   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-4692566846343221221-upcoming-0
I0708 14:24:01.006211   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:01.006229   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:01.006242   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:01.006251   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:24:01.006286   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:24:01.006320   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:24:01.006355   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:01.006371   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:24:01.006397   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:24:01.006480   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:24:11.557741   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:11.558003   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:11.558085   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:11.558947   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:11.558978   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:11.559735   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:11.559757   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:11.560324   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:11.560345   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:11.560841   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:11.560857   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:11.561489   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:11.561984   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:11.562182   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-5094354285624283051-upcoming-0
I0708 14:24:11.562207   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:11.562264   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:11.562286   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:11.562297   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:24:11.562333   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:24:11.562369   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:24:11.562423   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:24:11.562456   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:11.562468   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:24:11.562547   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:24:17.021057   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Node total 69 items received
I0708 14:24:22.208127   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:22.208337   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:22.208398   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:22.209279   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:22.209308   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:22.210062   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:22.210084   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:22.210575   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:22.210594   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:22.211088   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:22.211106   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:22.211731   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:22.212190   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:22.212376   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-1692827229457831555-upcoming-0
I0708 14:24:22.212398   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:22.212416   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:22.212429   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:22.212438   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:24:22.212473   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:24:22.212508   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:24:22.212548   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:24:22.212575   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:22.212588   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:24:22.212667   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:22:46.842593 +0530 IST m=+979.268796668 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:24:30.565720   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:24:30.566042   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 235.875Âµs
I0708 14:24:32.678455   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:32.678509   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:32.678521   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:32.678527   60673 taints.go:442] Overriding status of node ip-10-180-25-116.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:24:32.844458   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-one-zone-z1-dc794-rm6zl marked with priority 1 successfully
I0708 14:24:32.844595   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:32.844601   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:32.844735   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:32.844743   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:32.844862   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:32.844866   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:32.844987   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:32.844992   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:32.845143   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:32.845254   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:32.845297   60673 klogx.go:87] Pod default/scale-up-pod-a-78d7977858-b4v7w can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021-upcoming-0
I0708 14:24:32.845317   60673 klogx.go:87] failed to find place for default/scale-up-pod-b-78d7977858-6lx52: cannot put pod scale-up-pod-b-78d7977858-6lx52 on any node
I0708 14:24:32.845321   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:32.845325   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:32.845328   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:32.845330   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I0708 14:24:32.845334   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 is unschedulable
I0708 14:24:32.845341   60673 orchestrator.go:111] Upcoming 1 nodes
I0708 14:24:32.845426   60673 orchestrator.go:566] Pod default/scale-up-pod-b-78d7977858-6lx52 can't be scheduled on shoot--i585976--ca-test-three-zones-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:24:32.845450   60673 orchestrator.go:566] Pod default/scale-up-pod-b-78d7977858-6lx52 can't be scheduled on shoot--i585976--ca-test-three-zones-z2, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:24:32.845471   60673 orchestrator.go:566] Pod default/scale-up-pod-b-78d7977858-6lx52 can't be scheduled on shoot--i585976--ca-test-three-zones-z3, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I0708 14:24:32.845493   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z1-2073784451745845809 are not similar, labels do not match
I0708 14:24:32.845506   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z2-3157204786584625485 are not similar, labels do not match
I0708 14:24:32.845519   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z3-7534853301246300001 are not similar, labels do not match
I0708 14:24:32.845615   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z1
I0708 14:24:32.845618   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z2
I0708 14:24:32.845620   60673 orchestrator.go:153] No pod can fit to shoot--i585976--ca-test-three-zones-z3
I0708 14:24:32.845625   60673 waste.go:55] Expanding Node Group shoot--i585976--ca-test-one-zone-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I0708 14:24:32.845633   60673 orchestrator.go:184] Best option to resize: shoot--i585976--ca-test-one-zone-z1
I0708 14:24:32.845637   60673 orchestrator.go:188] Estimated 1 nodes needed in shoot--i585976--ca-test-one-zone-z1
I0708 14:24:32.845649   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z1-2073784451745845809 are not similar, labels do not match
I0708 14:24:32.845670   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z2-3157204786584625485 are not similar, labels do not match
I0708 14:24:32.845681   60673 compare_nodegroups.go:181] nodes template-node-for-shoot--i585976--ca-test-one-zone-z1-3094464598850391021 and template-node-for-shoot--i585976--ca-test-three-zones-z3-7534853301246300001 are not similar, labels do not match
I0708 14:24:32.845686   60673 orchestrator.go:215] No similar node groups found
I0708 14:24:32.845694   60673 orchestrator.go:257] Final scale-up plan: [{shoot--i585976--ca-test-one-zone-z1 1->2 (max: 2)}]
I0708 14:24:32.845702   60673 executor.go:147] Scale-up: setting group shoot--i585976--ca-test-one-zone-z1 size to 2
I0708 14:24:32.845710   60673 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i585976--ca-test-one-zone-z1 by 1
I0708 14:24:32.845739   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"616896", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i585976--ca-test-one-zone-z1 size to 2 instead of 1 (max: 2)
I0708 14:24:33.009746   60673 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I0708 14:24:33.080369   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"616896", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' (combined from similar events): Scale-up: group shoot--i585976--ca-test-one-zone-z1 size set to 2 instead of 1 (max: 2)
I0708 14:24:33.311344   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-b-78d7977858-6lx52", UID:"bb813d25-47ca-4597-b31d-621ff57b9c64", APIVersion:"v1", ResourceVersion:"616935", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i585976--ca-test-one-zone-z1 1->2 (max: 2)}]
I0708 14:24:42.617661   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.ReplicaSet total 24 items received
I0708 14:24:43.477094   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:43.477280   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:43.477337   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:43.478251   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:43.478279   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:43.479079   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:43.479102   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:43.479629   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:43.479649   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:43.480191   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:43.480211   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:43.480891   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:43.481000   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:24:43.481452   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:43.481643   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-2135523207528077317-upcoming-0
I0708 14:24:43.481666   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:43.481685   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:43.481697   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:43.481706   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:24:43.481740   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:24:43.481776   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:24:43.481817   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:24:43.481838   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:43.481849   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:24:43.481987   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:24:43.482071   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:24:43.482143   60673 static_autoscaler.go:655] Starting scale down
I0708 14:24:43.482245   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:53.956296   60673 static_autoscaler.go:306] Starting main loop
I0708 14:24:53.956576   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:53.956639   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:24:53.957565   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:24:53.957594   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:24:53.958409   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:53.958432   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:53.958996   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:53.959015   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:53.959543   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:24:53.959564   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:24:53.960299   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:53.960415   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:24:53.960900   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:24:53.961082   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-593620395070426678-upcoming-0
I0708 14:24:53.961104   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:24:53.961124   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:24:53.961138   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:24:53.961147   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:24:53.961181   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:24:53.961213   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:24:53.961254   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:24:53.961276   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:53.961288   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:24:53.961452   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:24:53.961540   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:24:53.961612   60673 static_autoscaler.go:655] Starting scale down
I0708 14:24:53.961716   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:24:54.599899   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.MachineClass total 10 items received
I0708 14:25:00.946963   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSINode total 16 items received
I0708 14:25:04.600702   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:04.600797   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:04.600822   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:04.601163   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:04.601173   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:04.601456   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:25:04.601464   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:25:04.601697   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:04.601705   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:04.601903   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:04.601910   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:04.602184   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:04.602224   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:25:04.602405   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:04.602478   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-7066691077147836441-upcoming-0
I0708 14:25:04.602487   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:04.602495   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:04.602500   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:04.602504   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:04.602516   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:04.602529   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:04.602545   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:04.602553   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:04.602557   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:04.602605   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:04.602636   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:04.602664   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:04.602703   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:14.681664   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Deployment total 20 items received
I0708 14:25:15.068130   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:15.068405   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:15.068485   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:15.069365   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:15.069392   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:15.070185   60673 mcm_manager.go:768] Nodes already existing in the worker pool one-zone
I0708 14:25:15.070212   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-25-116.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7927444Ki
I0708 14:25:15.070718   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:15.070738   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:15.071281   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:15.071301   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:15.072004   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:15.072098   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:25:15.072515   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:15.072730   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-7869999544743517535-upcoming-0
I0708 14:25:15.072753   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:15.072772   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:15.072785   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:15.072795   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:15.072828   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:15.072862   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:15.072912   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:15.072942   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:15.072954   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:15.073073   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:15.073155   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:15.073225   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:15.073337   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:18.569377   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.ReplicationController total 8 items received
I0708 14:25:25.630525   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:25.630735   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:25.630797   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:25.632747   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:25.632776   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:25.633469   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:25.633490   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:25.634067   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:25.634089   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:25.634764   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:25.634879   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:25:25.635468   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:25.635647   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-6346513007753578517-upcoming-0
I0708 14:25:25.635671   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:25.635690   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:25.635702   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:25.635710   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:25.635745   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:25.635780   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:25.635819   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:25.635840   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:25.635852   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:25.635994   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:25.636076   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:25.636144   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:25.636245   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:27.566081   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSIDriver total 0 items received
I0708 14:25:27.579413   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Pod total 316 items received
I0708 14:25:36.107024   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:36.107249   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:36.107322   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:36.109631   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:36.109658   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:36.110346   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:36.110368   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:36.110899   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:36.110917   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:36.111549   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:36.112206   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:36.112403   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-3848373653480244327-upcoming-0
I0708 14:25:36.112427   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:36.112445   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:36.112457   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:36.112466   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:36.112501   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:36.112532   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:36.112573   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:36.112598   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:36.112609   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:36.112764   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:36.112846   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:36.112916   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:36.113022   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:46.585173   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:46.585476   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:46.585540   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:46.587694   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:46.587721   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:46.588380   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:46.588401   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:46.588939   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:46.588961   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:46.589656   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:46.590291   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:46.590480   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-5999056789637759662-upcoming-0
I0708 14:25:46.590503   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:46.590523   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:46.590535   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:46.590544   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:46.590577   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:46.590614   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:46.590653   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:46.590673   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:46.590707   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:46.590833   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:46.590920   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:46.590992   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:46.591085   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:57.134533   60673 static_autoscaler.go:306] Starting main loop
I0708 14:25:57.134703   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:57.134751   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:25:57.136143   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:57.136169   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:57.136681   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:57.136702   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:57.137140   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:25:57.137154   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:25:57.137712   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:57.138216   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:25:57.138344   60673 klogx.go:87] Pod default/scale-up-pod-b-78d7977858-6lx52 can be moved to template-node-for-shoot--i585976--ca-test-one-zone-z1-1025166267129962940-upcoming-0
I0708 14:25:57.138364   60673 filter_out_schedulable.go:120] 1 pods marked as unschedulable can be scheduled.
I0708 14:25:57.138380   60673 filter_out_schedulable.go:75] Schedulable pods present
I0708 14:25:57.138391   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:25:57.138399   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:25:57.138432   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:25:57.138464   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:25:57.138500   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:25:57.138520   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:57.138531   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:25:57.138639   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:25:57.138701   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:25:57.138759   60673 static_autoscaler.go:655] Starting scale down
I0708 14:25:57.138838   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:25:59.805817   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.DaemonSet total 116 items received
I0708 14:26:07.607326   60673 static_autoscaler.go:306] Starting main loop
I0708 14:26:07.607534   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:07.607597   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:07.607637   60673 taints.go:442] Overriding status of node ip-10-180-24-101.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I0708 14:26:07.609754   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:07.609784   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:07.610465   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:07.610485   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:07.610992   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:07.611010   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:07.611669   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:07.612284   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:26:07.612308   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:26:07.612331   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:26:07.612346   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:26:07.612354   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:26:07.612389   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:26:07.612427   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:26:07.612466   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:26:07.612491   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:07.612503   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:26:07.612631   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:26:07.612717   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:26:07.612784   60673 static_autoscaler.go:655] Starting scale down
I0708 14:26:07.612889   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:18.227736   60673 static_autoscaler.go:306] Starting main loop
I0708 14:26:18.227971   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:18.228033   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:18.229946   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:18.229971   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:18.230640   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:18.230661   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:18.231206   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:18.231226   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:18.231885   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:18.231957   60673 clusterstate.go:266] Scale up in group shoot--i585976--ca-test-one-zone-z1 finished successfully in 1m45.217875458s
I0708 14:26:18.232047   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:26:18.232071   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:26:18.232091   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:26:18.232105   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:26:18.232114   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:26:18.232149   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:26:18.232182   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:26:18.232212   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:18.232227   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:26:18.232267   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:26:18.232433   60673 klogx.go:87] Node ip-10-180-24-101.eu-west-1.compute.internal - cpu requested is 24.5312% of allocatable
I0708 14:26:18.232537   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:26:18.232577   60673 cluster.go:156] Simulating node ip-10-180-24-101.eu-west-1.compute.internal removal
I0708 14:26:18.232626   60673 cluster.go:174] node ip-10-180-24-101.eu-west-1.compute.internal may be removed
I0708 14:26:18.232659   60673 nodes.go:84] ip-10-180-24-101.eu-west-1.compute.internal is unneeded since 2024-07-08 14:26:18.227673 +0530 IST m=+1190.653615543 duration 0s
I0708 14:26:18.232741   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:26:18.232800   60673 static_autoscaler.go:655] Starting scale down
I0708 14:26:18.232844   60673 nodes.go:126] ip-10-180-24-101.eu-west-1.compute.internal was unneeded for 0s
I0708 14:26:18.232924   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:18.470906   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-24-101.eu-west-1.compute.internal
I0708 14:26:25.567306   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.StatefulSet total 6 items received
I0708 14:26:29.012611   60673 static_autoscaler.go:306] Starting main loop
I0708 14:26:29.012882   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:29.012948   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:29.014914   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:29.014943   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:29.015705   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:29.015728   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:29.016272   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:29.016293   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:29.016893   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:29.017004   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:26:29.017028   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:26:29.017046   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:26:29.017057   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:26:29.017066   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:26:29.017100   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:26:29.017133   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:26:29.017185   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:26:29.017209   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:29.017221   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:26:29.017396   60673 klogx.go:87] Node ip-10-180-24-101.eu-west-1.compute.internal - cpu requested is 24.5312% of allocatable
I0708 14:26:29.017508   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:26:29.017540   60673 cluster.go:156] Simulating node ip-10-180-24-101.eu-west-1.compute.internal removal
I0708 14:26:29.017588   60673 cluster.go:174] node ip-10-180-24-101.eu-west-1.compute.internal may be removed
I0708 14:26:29.017624   60673 nodes.go:84] ip-10-180-24-101.eu-west-1.compute.internal is unneeded since 2024-07-08 14:26:18.227673 +0530 IST m=+1190.653615543 duration 10.784847458s
I0708 14:26:29.017709   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:21:53.650047 +0530 IST m=+926.076316418 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:26:29.017766   60673 static_autoscaler.go:655] Starting scale down
I0708 14:26:29.017814   60673 nodes.go:126] ip-10-180-24-101.eu-west-1.compute.internal was unneeded for 10.784847458s
I0708 14:26:29.017858   60673 klogx.go:87] Considering node ip-10-180-24-101.eu-west-1.compute.internal for standard scale down
I0708 14:26:29.448463   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-24-101.eu-west-1.compute.internal
I0708 14:26:29.448541   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-24-101.eu-west-1.compute.internal"
I0708 14:26:29.448653   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-24-101.eu-west-1.compute.internal", UID:"635fdce9-be63-419d-b17f-d6995fe22c46", APIVersion:"v1", ResourceVersion:"617810", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:26:29.448879   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:26:29.681216   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"617814", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-24-101.eu-west-1.compute.internal"
I0708 14:26:30.567378   60673 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I0708 14:26:30.567665   60673 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 215.083Âµs
I0708 14:26:31.566071   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSIStorageCapacity total 4 items received
I0708 14:26:34.450533   60673 drain.go:131] All pods removed from ip-10-180-24-101.eu-west-1.compute.internal
I0708 14:26:34.450695   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-24-101.eu-west-1.compute.internal]
I0708 14:26:34.762161   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-one-zone-z1-dc794-r9w57 marked with priority 1 successfully
I0708 14:26:34.762195   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-one-zone-z1-dc794-r9w57:ip-10-180-24-101.eu-west-1.compute.internal]
I0708 14:26:34.926174   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-one-zone-z1 size decreased to 1 
I0708 14:26:34.926676   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"617880", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-24-101.eu-west-1.compute.internal removed
I0708 14:26:39.936646   60673 static_autoscaler.go:306] Starting main loop
I0708 14:26:39.936911   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:39.936977   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:39.939133   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:39.939161   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:39.939925   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:39.939950   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:39.940493   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:39.940512   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:39.941165   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:39.941293   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:26:39.941315   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:26:39.941335   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:26:39.941346   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:26:39.941355   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:26:39.941390   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:26:39.941422   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:26:39.941466   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:26:39.941493   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:39.941505   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:26:39.941610   60673 eligibility.go:113] Skipping ip-10-180-24-101.eu-west-1.compute.internal from delete consideration - the node is currently being deleted
I0708 14:26:39.941711   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:26:39.941794   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:26:29.012534 +0530 IST m=+1201.438463001 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:26:39.941864   60673 static_autoscaler.go:655] Starting scale down
I0708 14:26:39.941972   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:50.409953   60673 static_autoscaler.go:306] Starting main loop
I0708 14:26:50.410229   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:50.410295   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:26:50.412470   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:50.412496   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:50.413188   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:50.413209   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:50.413733   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:26:50.413749   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:26:50.414338   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:50.414452   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:26:50.414474   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:26:50.414494   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:26:50.414506   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:26:50.414515   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:26:50.414549   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:26:50.414587   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:26:50.414635   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:26:50.414657   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:26:50.414668   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:26:50.414769   60673 eligibility.go:113] Skipping ip-10-180-24-101.eu-west-1.compute.internal from delete consideration - the node is currently being deleted
I0708 14:26:50.414870   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:26:50.414957   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:26:29.012534 +0530 IST m=+1201.438463001 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:26:50.415024   60673 static_autoscaler.go:655] Starting scale down
I0708 14:26:50.415138   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:01.018943   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:01.019116   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:01.019191   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:01.193805   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-one-zone-z1-dc794-r9w57 marked with priority 1 successfully
I0708 14:27:01.195783   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:01.195812   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:01.196555   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:01.196583   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:01.197127   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:01.197149   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:01.197736   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:01.197847   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:27:01.197921   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:01.197941   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:01.197962   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:01.197974   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:01.197982   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:01.198017   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:01.198051   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:01.198087   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:01.198113   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:01.198125   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:01.198260   60673 eligibility.go:162] Node ip-10-180-25-116.eu-west-1.compute.internal unremovable: cpu requested (76.6146% of allocatable) is above the scale-down utilization threshold
I0708 14:27:01.198341   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:26:29.012534 +0530 IST m=+1201.438463001 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:27:01.198411   60673 static_autoscaler.go:655] Starting scale down
I0708 14:27:01.198507   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:05.692835   60673 reflector.go:808] github.com/gardener/machine-controller-manager/pkg/client/informers/externalversions/factory.go:120: Watch close - *v1alpha1.Machine total 74 items received
I0708 14:27:11.665108   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:11.665310   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:11.665372   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:11.667392   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:11.667422   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:11.668078   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:11.668094   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:11.668638   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:11.668660   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:11.669278   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:11.669317   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:11.669331   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:11.669351   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0176d4c39de14d020
I0708 14:27:11.669424   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:27:11.669448   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:11.669461   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:11.669474   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0176d4c39de14d020, skipping
I0708 14:27:11.669526   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:11.669551   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:11.669570   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:11.669581   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:11.669593   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:11.669628   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:11.669663   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:11.669704   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:11.669725   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:11.669738   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:11.669860   60673 klogx.go:87] Node ip-10-180-25-116.eu-west-1.compute.internal - cpu requested is 24.5312% of allocatable
I0708 14:27:11.669902   60673 cluster.go:156] Simulating node ip-10-180-25-116.eu-west-1.compute.internal removal
I0708 14:27:11.669956   60673 cluster.go:174] node ip-10-180-25-116.eu-west-1.compute.internal may be removed
I0708 14:27:11.669996   60673 nodes.go:84] ip-10-180-25-116.eu-west-1.compute.internal is unneeded since 2024-07-08 14:27:11.665031 +0530 IST m=+1244.090907710 duration 0s
I0708 14:27:11.670081   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:26:29.012534 +0530 IST m=+1201.438463001 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:27:11.670136   60673 static_autoscaler.go:655] Starting scale down
I0708 14:27:11.670180   60673 nodes.go:126] ip-10-180-25-116.eu-west-1.compute.internal was unneeded for 0s
I0708 14:27:11.670270   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:12.226995   60673 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-25-116.eu-west-1.compute.internal
I0708 14:27:22.739411   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:22.739690   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:22.739752   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:22.740661   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:27:22.741815   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:22.741841   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:22.742541   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:22.742557   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:22.743143   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:22.743165   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:22.743750   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:22.743789   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:22.743802   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:22.743822   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0176d4c39de14d020
I0708 14:27:22.743890   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:27:22.743918   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:22.743930   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:22.743944   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0176d4c39de14d020, skipping
I0708 14:27:22.743995   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:22.744017   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:22.744038   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:22.744050   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:22.744059   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:22.744094   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:22.744131   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:22.744169   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:22.744193   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:22.744204   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:22.744324   60673 klogx.go:87] Node ip-10-180-25-116.eu-west-1.compute.internal - cpu requested is 24.5312% of allocatable
I0708 14:27:22.744368   60673 cluster.go:156] Simulating node ip-10-180-25-116.eu-west-1.compute.internal removal
I0708 14:27:22.744419   60673 cluster.go:174] node ip-10-180-25-116.eu-west-1.compute.internal may be removed
I0708 14:27:22.744462   60673 nodes.go:84] ip-10-180-25-116.eu-west-1.compute.internal is unneeded since 2024-07-08 14:27:11.665031 +0530 IST m=+1244.090907710 duration 11.074288833s
I0708 14:27:22.744552   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:26:29.012534 +0530 IST m=+1201.438463001 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=false
I0708 14:27:22.744616   60673 static_autoscaler.go:655] Starting scale down
I0708 14:27:22.744666   60673 nodes.go:126] ip-10-180-25-116.eu-west-1.compute.internal was unneeded for 11.074288833s
I0708 14:27:22.744709   60673 klogx.go:87] Considering node ip-10-180-25-116.eu-west-1.compute.internal for standard scale down
I0708 14:27:23.202622   60673 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-25-116.eu-west-1.compute.internal
I0708 14:27:23.202709   60673 actuator.go:147] Scale-down: removing empty node "ip-10-180-25-116.eu-west-1.compute.internal"
I0708 14:27:23.202894   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-25-116.eu-west-1.compute.internal", UID:"1e71fa20-c684-4e6e-8527-268875381973", APIVersion:"v1", ResourceVersion:"618152", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I0708 14:27:23.203019   60673 actuator.go:242] Scale-down: waiting 5s before trying to delete nodes
I0708 14:27:23.436461   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"618158", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-25-116.eu-west-1.compute.internal"
I0708 14:27:25.573440   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Node total 123 items received
I0708 14:27:28.116470   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Service total 4 items received
I0708 14:27:28.204576   60673 drain.go:131] All pods removed from ip-10-180-25-116.eu-west-1.compute.internal
I0708 14:27:28.204707   60673 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-25-116.eu-west-1.compute.internal]
I0708 14:27:28.372012   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-one-zone-z1-dc794-rm6zl marked with priority 1 successfully
I0708 14:27:28.372068   60673 mcm_manager.go:534] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i585976--ca-test-one-zone-z1-dc794-rm6zl:ip-10-180-25-116.eu-west-1.compute.internal]
I0708 14:27:28.534485   60673 mcm_manager.go:588] MachineDeployment shoot--i585976--ca-test-one-zone-z1 size decreased to 0 
I0708 14:27:28.534763   60673 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"93315a0c-cc56-4eff-baf3-a9f5b1e850af", APIVersion:"v1", ResourceVersion:"618246", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-25-116.eu-west-1.compute.internal removed
I0708 14:27:33.670667   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:33.670933   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:33.670994   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:33.671955   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:27:33.671975   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:27:33.673126   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:33.673153   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:33.673862   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:33.673887   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:33.674403   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:33.674420   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:33.675012   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:33.675054   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:33.675071   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:33.675090   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0176d4c39de14d020
I0708 14:27:33.675162   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:27:33.675185   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:33.675232   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:33.675253   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0176d4c39de14d020, skipping
I0708 14:27:33.675315   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:33.675342   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:33.675361   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:33.675374   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:33.675383   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:33.675418   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:33.675450   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:33.675498   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:33.675521   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:33.675533   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:33.675554   60673 pre_filtering_processor.go:67] Skipping ip-10-180-25-116.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:27:33.675631   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:27:22.739334 +0530 IST m=+1255.165196543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:27:43.566560   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Job total 6 items received
I0708 14:27:44.144128   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:44.144238   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:44.144274   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:44.144683   60673 taints.go:406] Removing autoscaler soft taint when creating template from node
I0708 14:27:44.144692   60673 taints.go:403] Removing autoscaler taint when creating template from node
I0708 14:27:44.145331   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:44.145344   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:44.145785   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:44.145792   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:44.146020   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:44.146032   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:44.146270   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:44.146284   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:44.146291   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:44.146299   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0176d4c39de14d020
I0708 14:27:44.146336   60673 static_autoscaler.go:432] 1 unregistered nodes present
I0708 14:27:44.146345   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:44.146350   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:44.146355   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0176d4c39de14d020, skipping
I0708 14:27:44.146374   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:44.146391   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:44.146399   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:44.146404   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:44.146408   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:44.146421   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:44.146433   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:44.146451   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:44.146463   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:44.146467   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:44.146475   60673 pre_filtering_processor.go:67] Skipping ip-10-180-25-116.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I0708 14:27:44.146508   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:27:22.739334 +0530 IST m=+1255.165196543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:27:54.652977   60673 static_autoscaler.go:306] Starting main loop
I0708 14:27:54.653144   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:54.653205   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:27:54.819560   60673 mcm_manager.go:562] Machine shoot--i585976--ca-test-one-zone-z1-dc794-rm6zl marked with priority 1 successfully
I0708 14:27:54.820027   60673 mcm_manager.go:779] Generating node template only using nodeTemplate from MachineClass shoot--i585976--ca-test-one-zone-z1-4e9b4: template resources-> cpu: 2,memory: 8Gi
I0708 14:27:54.820470   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:54.820481   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:54.820779   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:54.820789   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:54.821074   60673 mcm_manager.go:768] Nodes already existing in the worker pool three-zones
I0708 14:27:54.821084   60673 mcm_manager.go:770] Worker pool node used to form template is ip-10-180-29-171.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7841420Ki
I0708 14:27:54.821409   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:54.821445   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:54.821454   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:54.821466   60673 clusterstate.go:648] Nodegroup is nil for aws:///eu-west-1b/i-0176d4c39de14d020
I0708 14:27:54.821519   60673 static_autoscaler.go:432] 2 unregistered nodes present
I0708 14:27:54.821539   60673 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-0176d4c39de14d020"
I0708 14:27:54.821545   60673 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-0176d4c39de14d020, it's either been removed or it's not managed by this controller
W0708 14:27:54.821552   60673 static_autoscaler.go:763] No node group for node aws:///eu-west-1b/i-0176d4c39de14d020, skipping
I0708 14:27:54.821591   60673 filter_out_schedulable.go:63] Filtering out schedulables
I0708 14:27:54.821605   60673 filter_out_schedulable.go:120] 0 pods marked as unschedulable can be scheduled.
I0708 14:27:54.821616   60673 filter_out_schedulable.go:83] No schedulable pods
I0708 14:27:54.821624   60673 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I0708 14:27:54.821628   60673 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I0708 14:27:54.821650   60673 static_autoscaler.go:567] No unschedulable pods
I0708 14:27:54.821666   60673 static_autoscaler.go:590] Calculating unneeded nodes
I0708 14:27:54.821689   60673 pre_filtering_processor.go:67] Skipping ip-10-180-29-171.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I0708 14:27:54.821708   60673 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1b/i-030beac746ccd3da0, it's not managed by this controller
I0708 14:27:54.821715   60673 pre_filtering_processor.go:57] Node ip-10-180-7-226.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I0708 14:27:54.821762   60673 static_autoscaler.go:634] Scale down status: lastScaleUpTime=2024-07-08 14:24:32.678438 +0530 IST m=+1085.104510835 lastScaleDownDeleteTime=2024-07-08 14:27:22.739334 +0530 IST m=+1255.165196543 lastScaleDownFailTime=2024-07-08 13:05:12.156739 +0530 IST m=-3597.019801832 scaleDownForbidden=false scaleDownInCooldown=true
I0708 14:27:57.116669   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PodDisruptionBudget total 0 items received
I0708 14:28:04.142873   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Namespace total 2 items received
I0708 14:28:05.287105   60673 static_autoscaler.go:306] Starting main loop
I0708 14:28:05.287303   60673 taints.go:442] Overriding status of node ip-10-180-29-171.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I0708 14:28:05.287363   60673 taints.go:442] Overriding status of node ip-10-180-7-226.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
E0708 14:28:05.287475   60673 static_autoscaler.go:351] Failed to refresh cloud provider config: machine-controller-manager is offline. Cluster autoscaler operations would be suspended.
I0708 14:28:11.888940   60673 reflector.go:808] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.PersistentVolumeClaim total 16 items received
